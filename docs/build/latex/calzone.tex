%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}

\usepackage{nbsphinx}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{calzone}
\date{Oct 01, 2024}
\release{develop}
\author{Kwok Lung Jason Fan}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxAtStartPar
calzone is a Python package for calculation of various calibration metrics. This work is credited to Kwok Lung (Jason) Fan and Qian Cao.

\sphinxAtStartPar
The calzone package provides a suite of tools for assessing and improving the calibration of machine learning models, particularly in binary classification tasks. It offers various calibration metrics, methods for generating and manipulating calibration data, and visualization tools for reliability diagrams. Whether you’re working on model evaluation, uncertainty quantification, or improving the reliability of probabilistic predictions, calzone offers the utilities you need.

\sphinxAtStartPar
Key features of calzone include:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Calculation of various calibration metrics (e.g., ECE, MCE, Hosmer\sphinxhyphen{}Lemeshow test, spiegelhalter z test, etc.)

\item {} 
\sphinxAtStartPar
Visualization functions for reliability diagrams

\item {} 
\sphinxAtStartPar
Bootstrapping capabilities for confidence interval estimation

\item {} 
\sphinxAtStartPar
Subgroup analysis for calibration metrics

\item {} 
\sphinxAtStartPar
Provides graphical user interface for easy calculation

\item {} 
\sphinxAtStartPar
Provides command line interface scripts for batch processing

\end{itemize}

\sphinxAtStartPar
To accurately assess the calibration of machine learning models, it is essential to have a comprehensive and reprensative dataset with sufficient coverage of the prediction space. The calibration metrics is not meaningful if the dataset is not representative of true intended population.

\sphinxAtStartPar
We hope you find calzone useful in your machine learning and data science projects!

\sphinxstepscope


\chapter{Quick Start}
\label{\detokenize{notebooks/quickstart:Quick-Start}}\label{\detokenize{notebooks/quickstart::doc}}
\sphinxAtStartPar
The tutorial provides a quick start to the calzone package. Including the installation and the basic command line interface useage.


\section{Installation}
\label{\detokenize{notebooks/quickstart:Installation}}
\sphinxAtStartPar
calzone dependencies are numpy, scipy, statsmodels and matplotlib. If you are experienced developer, you probably already have numpy, scipy and matplolib installed. If you don’t have a package install, you can install them with conda

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[ ]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{conda} \PYG{n}{install} \PYG{n}{numpy}
\PYG{n}{conda} \PYG{n}{install} \PYG{n}{scipy}
\PYG{n}{conda} \PYG{n}{install} \PYG{n}{matplotlib}
\PYG{n}{conda} \PYG{n}{install} \PYG{n}{statsmodels}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Alternatively, you can install the dependencies with pip

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[ ]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{pip} \PYG{n}{install} \PYG{n}{numpy}
\PYG{n}{pip} \PYG{n}{install} \PYG{n}{scipy}
\PYG{n}{pip} \PYG{n}{install} \PYG{n}{matplotlib}
\PYG{n}{pip} \PYG{n}{install} \PYG{n}{statsmodels}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Then, you can process to install the calzone package from github if you only want to use the calculator inside you python script:

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[ ]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{pip} \PYG{n}{install} \PYG{o}{\PYGZhy{}}\PYG{n}{e} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{git+https://github.com/DIDSR/calzone.git}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
If you want to run the command line interface or GUI interface, you need to clone the github repository. Notice that the GUI interface require install nicegui using \sphinxcode{\sphinxupquote{pip install nicegui}}.

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[ ]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{git} \PYG{n}{clone} \PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{DIDSR}\PYG{o}{/}\PYG{n}{calzone}\PYG{o}{.}\PYG{n}{git}
\PYG{n}{cd} \PYG{n}{calzone}
\PYG{c+c1}{\PYGZsh{} install calzone}
\PYG{n}{pip} \PYG{n}{install} \PYG{o}{\PYGZhy{}}\PYG{n}{e} \PYG{o}{.}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Command line interface}
\label{\detokenize{notebooks/quickstart:Command-line-interface}}
\sphinxAtStartPar
First, you need to prepare your dataset in a specified format. The dataset should be a CSV file with the following columns:

\sphinxAtStartPar
proba\_0, proba\_1, …, proba\_n, label

\sphinxAtStartPar
where n \textgreater{}= 1.

\sphinxAtStartPar
Or if you have subgroups, the dataset should be a CSV file with the following columns:

\sphinxAtStartPar
proba\_0, proba\_1, …, proba\_n, subgroup\_1, subgroup\_2, …, subgroup\_m, label

\sphinxAtStartPar
where n \textgreater{}= 1 and m \textgreater{}= 1.

\sphinxAtStartPar
In the case of multi\sphinxhyphen{}class, you need to specify the class\sphinxhyphen{}of\sphinxhyphen{}interest, and the problem will be treated as 1\sphinxhyphen{}vs\sphinxhyphen{}all binary classification. To test the full calibration of the whole model, you need to test the calibration of each class.

\sphinxAtStartPar
The program also works if your csv file has no header.It will assume the first {[}:\sphinxhyphen{}1{]} columns are the probabilities and the last column is the label.

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[2]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} For illuration purpose , I will use build\PYGZhy{}in class to generate fake data. Do not run this cell in real case.}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} A well\PYGZhy{}calibrated dataset and miscalibrated dataset are provided in the example folder}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{123}\PYG{p}{)}
\PYG{n}{fakedata\PYGZus{}generator} \PYG{o}{=} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}\PYG{p}{(}\PYG{n}{alpha\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{beta\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}
\PYG{n}{X}\PYG{p}{,} \PYG{n}{y\PYGZus{}true} \PYG{o}{=} \PYG{n}{fakedata\PYGZus{}generator}\PYG{o}{.}\PYG{n}{generate\PYGZus{}data}\PYG{p}{(}\PYG{l+m+mi}{5000}\PYG{p}{)}
\PYG{n}{X2}\PYG{p}{,} \PYG{n}{y\PYGZus{}true2} \PYG{o}{=} \PYG{n}{fakedata\PYGZus{}generator}\PYG{o}{.}\PYG{n}{generate\PYGZus{}data}\PYG{p}{(}\PYG{l+m+mi}{5000}\PYG{p}{)}
\PYG{n}{X2} \PYG{o}{=} \PYG{n}{fakedata\PYGZus{}generator}\PYG{o}{.}\PYG{n}{linear\PYGZus{}miscal}\PYG{p}{(}\PYG{n}{X2}\PYG{p}{,} \PYG{n}{miscal\PYGZus{}scale}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n}{df} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{column\PYGZus{}stack}\PYG{p}{(}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{X}\PYG{p}{)}\PYG{o}{.}\PYG{n}{tolist}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{y\PYGZus{}true}\PYG{p}{)}\PYG{o}{.}\PYG{n}{tolist}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{df\PYGZus{}miscal} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{column\PYGZus{}stack}\PYG{p}{(}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{X2}\PYG{p}{)}\PYG{o}{.}\PYG{n}{tolist}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{y\PYGZus{}true2}\PYG{p}{)}\PYG{o}{.}\PYG{n}{tolist}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{savetxt}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{df}\PYG{p}{,} \PYG{n}{delimiter}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{header}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{proba\PYGZus{}0,proba\PYGZus{}1,label}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{comments}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{savetxt}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../../../example\PYGZus{}data/simulated\PYGZus{}misdata.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{df\PYGZus{}miscal}\PYG{p}{,} \PYG{n}{delimiter}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{header}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{proba\PYGZus{}0,proba\PYGZus{}1,label}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{comments}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Create data for subgroup analysis}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{c+c1}{\PYGZsh{} Create dataframes for each subgroup}
\PYG{n}{df\PYGZus{}A} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{proba\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{X}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{proba\PYGZus{}1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{X}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subgroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{label}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{y\PYGZus{}true}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n}{df\PYGZus{}B} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{proba\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{X2}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{proba\PYGZus{}1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{X2}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subgroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{B}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{label}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{y\PYGZus{}true2}\PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Merge the dataframes}
\PYG{n}{df\PYGZus{}merged} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{concat}\PYG{p}{(}\PYG{p}{[}\PYG{n}{df\PYGZus{}A}\PYG{p}{,} \PYG{n}{df\PYGZus{}B}\PYG{p}{]}\PYG{p}{,} \PYG{n}{ignore\PYGZus{}index}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Rename the \PYGZsq{}subgroup\PYGZsq{} column to \PYGZsq{}subgroup\PYGZus{}1\PYGZsq{}}
\PYG{n}{df\PYGZus{}merged} \PYG{o}{=} \PYG{n}{df\PYGZus{}merged}\PYG{o}{.}\PYG{n}{rename}\PYG{p}{(}\PYG{n}{columns}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subgroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subgroup\PYGZus{}1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n}{df\PYGZus{}merged}\PYG{o}{.}\PYG{n}{to\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}data\PYGZus{}subgroup.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{index}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
To use CLI, you can use the script in the calzone directory. The program will save the metrics into the output csv file with the CI(if you turn on boostrap). The program will also save the relibaility diagram if you apply \textendash{}plot flag. There is an optional flag \textendash{}prevalence\_adjustment which try to derive the original model prevalence and apply prevalence adjustment. See more on prevalence adjustment in the prevalecne adjustment notebook.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[4]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{o}{\PYGZpc{}}\PYG{k}{run} ../../../cal\PYGZus{}metrics.py \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{csv\PYGZus{}file} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata.csv}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{metrics} \PYG{n+nb}{all} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{n\PYGZus{}bootstrap} \PYG{l+m+mi}{1000} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{bootstrap\PYGZus{}ci} \PYG{l+m+mf}{0.95} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate} \PYG{l+m+mi}{1} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{num\PYGZus{}bins} \PYG{l+m+mi}{10} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{save\PYGZus{}metrics} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata\PYGZus{}result.csv}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{plot} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{plot\PYGZus{}bins} \PYG{l+m+mi}{10} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{save\PYGZus{}plot} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata\PYGZus{}result.png}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{verbose} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{save\PYGZus{}diagram\PYGZus{}output} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata\PYGZus{}diagram\PYGZus{}output.csv}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} save\PYGZus{}diagram\PYGZus{}output only when you want to save the reliability diagram output}
\PYG{c+c1}{\PYGZsh{}\PYGZhy{}\PYGZhy{}prevalence\PYGZus{}adjustment \PYGZsh{} only when you want to apply prevalence adjustment}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Metrics with bootstrap confidence intervals:
SpiegelhalterZ score: 0.376 (-1.615, 2.515)
SpiegelhalterZ p-value: 0.707 (0.010, 0.973)
ECE-H topclass: 0.01 (0.006, 0.022)
ECE-H: 0.012 (0.011, 0.025)
MCE-H topclass: 0.039 (0.016, 0.076)
MCE-H: 0.048 (0.033, 0.105)
HL-H score: 8.885 (6.789, 34.674)
HL-H p-value: 0.352 (0.000, 0.56)
ECE-C topclass: 0.009 (0.008, 0.021)
ECE-C: 0.009 (0.008, 0.022)
MCE-C topclass: 0.021 (0.019, 0.068)
MCE-C: 0.023 (0.02, 0.071)
HL-C score: 3.695 (4.484, 30.483)
HL-C p-value: 0.884 (0.000, 0.811)
COX coef: 0.994 (0.938, 1.053)
COX intercept: -0.045 (-0.125, 0.028)
COX coef lowerci: 0.937 (0.884, 0.993)
COX coef upperci: 1.051 (0.992, 1.113)
COX intercept lowerci: -0.123 (-0.204, -0.051)
COX intercept upperci: 0.034 (-0.047, 0.106)
COX ICI: 0.006 (0.001, 0.016)
Loess ICI: 0.006 (0.003, 0.016)
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=702\sphinxpxdimen,height=530\sphinxpxdimen]{{notebooks_quickstart_15_1}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
We can also test it on a miscalibrated dataset

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[5]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{o}{\PYGZpc{}}\PYG{k}{run} ../../../cal\PYGZus{}metrics.py \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{csv\PYGZus{}file} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}misdata.csv}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{metrics} \PYG{n+nb}{all} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{n\PYGZus{}bootstrap} \PYG{l+m+mi}{1000} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{bootstrap\PYGZus{}ci} \PYG{l+m+mf}{0.95} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate} \PYG{l+m+mi}{1} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{num\PYGZus{}bins} \PYG{l+m+mi}{10} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{save\PYGZus{}metrics} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}misdata\PYGZus{}result.csv}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{plot} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{plot\PYGZus{}bins} \PYG{l+m+mi}{10} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{save\PYGZus{}plot} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}misdata\PYGZus{}result.png}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{verbose}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Metrics with bootstrap confidence intervals:
SpiegelhalterZ score: 27.936 (24.343, 31.373)
SpiegelhalterZ p-value: 0. (0., 0.)
ECE-H topclass: 0.077 (0.067, 0.087)
ECE-H: 0.077 (0.068, 0.088)
MCE-H topclass: 0.133 (0.107, 0.176)
MCE-H: 0.163 (0.13, 0.235)
HL-H score: 910.439 (711.575, 1170.693)
HL-H p-value: 0. (0., 0.)
ECE-C topclass: 0.074 (0.066, 0.085)
ECE-C: 0.075 (0.064, 0.086)
MCE-C topclass: 0.141 (0.126, 0.183)
MCE-C: 0.140 (0.114, 0.180)
HL-C score: 2246.171 (1415.309, 3702.911)
HL-C p-value: 0. (0., 0.)
COX coef: 0.507 (0.478, 0.540)
COX intercept: 0.000 (-0.073, 0.079)
COX coef lowerci: 0.478 (0.451, 0.509)
COX coef upperci: 0.536 (0.506, 0.571)
COX intercept lowerci: -0.078 (-0.153, 0.001)
COX intercept upperci: 0.079 (0.006, 0.157)
COX ICI: 0.077 (0.069, 0.086)
Loess ICI: 0.07 (0.061, 0.079)
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=702\sphinxpxdimen,height=530\sphinxpxdimen]{{notebooks_quickstart_17_1}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
If your data has subgroup in it, simply run the script with the same argument as the one above. It will automatically detect the subgroup and generate the corresponding plots and metrics for each subgroup as well as the overall plot and metrics.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[6]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{o}{\PYGZpc{}}\PYG{k}{run} ../../../cal\PYGZus{}metrics.py \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{csv\PYGZus{}file} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}data\PYGZus{}subgroup.csv}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{metrics} \PYG{n+nb}{all} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{n\PYGZus{}bootstrap} \PYG{l+m+mi}{1000} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{bootstrap\PYGZus{}ci} \PYG{l+m+mf}{0.95} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate} \PYG{l+m+mi}{1} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{num\PYGZus{}bins} \PYG{l+m+mi}{10} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{save\PYGZus{}metrics} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}data\PYGZus{}subgroup\PYGZus{}result.csv}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{plot} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{plot\PYGZus{}bins} \PYG{l+m+mi}{10} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{save\PYGZus{}plot} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}data\PYGZus{}subgroup\PYGZus{}result.png}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{verbose}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Metrics with bootstrap confidence intervals:
SpiegelhalterZ score: 18.327 (15.680, 20.858)
SpiegelhalterZ p-value: 0. (0., 0.)
ECE-H topclass: 0.042 (0.035, 0.048)
ECE-H: 0.042 (0.036, 0.049)
MCE-H topclass: 0.055 (0.043, 0.085)
MCE-H: 0.063 (0.054, 0.109)
HL-H score: 429.732 (332.85, 565.169)
HL-H p-value: 0. (0., 0.)
ECE-C topclass: 0.042 (0.034, 0.048)
ECE-C: 0.038 (0.032, 0.046)
MCE-C topclass: 0.065 (0.055, 0.092)
MCE-C: 0.064 (0.054, 0.087)
HL-C score: 1138.842 (748.777, 1819.374)
HL-C p-value: 0. (0., 0.)
COX coef: 0.668 (0.641, 0.699)
COX intercept: -0.02 (-0.072, 0.033)
COX coef lowerci: 0.641 (0.614, 0.670)
COX coef upperci: 0.696 (0.667, 0.728)
COX intercept lowerci: -0.074 (-0.127, -0.021)
COX intercept upperci: 0.034 (-0.017, 0.088)
COX ICI: 0.049 (0.043, 0.055)
Loess ICI: 0.037 (0.032, 0.043)
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=702\sphinxpxdimen,height=530\sphinxpxdimen]{{notebooks_quickstart_19_1}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Metrics for subgroup\_1\_group\_A with bootstrap confidence intervals:
SpiegelhalterZ score: 0.376 (-1.654, 2.308)
SpiegelhalterZ p-value: 0.707 (0.017, 0.978)
ECE-H topclass: 0.01 (0.006, 0.022)
ECE-H: 0.012 (0.010, 0.026)
MCE-H topclass: 0.039 (0.017, 0.076)
MCE-H: 0.048 (0.034, 0.103)
HL-H score: 8.885 (6.74, 36.214)
HL-H p-value: 0.352 (0.000, 0.565)
ECE-C topclass: 0.009 (0.007, 0.021)
ECE-C: 0.009 (0.008, 0.022)
MCE-C topclass: 0.021 (0.017, 0.070)
MCE-C: 0.023 (0.019, 0.072)
HL-C score: 3.695 (4.792, 30.155)
HL-C p-value: 0.884 (0.000, 0.78)
COX coef: 0.994 (0.942, 1.056)
COX intercept: -0.045 (-0.130, 0.031)
COX coef lowerci: 0.937 (0.888, 0.996)
COX coef upperci: 1.051 (0.996, 1.117)
COX intercept lowerci: -0.123 (-0.21, -0.048)
COX intercept upperci: 0.034 (-0.051, 0.109)
COX ICI: 0.006 (0.001, 0.016)
Loess ICI: 0.006 (0.003, 0.016)
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=702\sphinxpxdimen,height=545\sphinxpxdimen]{{notebooks_quickstart_19_3}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Metrics for subgroup\_1\_group\_B with bootstrap confidence intervals:
SpiegelhalterZ score: 27.936 (25.005, 31.623)
SpiegelhalterZ p-value: 0. (0., 0.)
ECE-H topclass: 0.077 (0.068, 0.087)
ECE-H: 0.077 (0.069, 0.088)
MCE-H topclass: 0.133 (0.110, 0.177)
MCE-H: 0.163 (0.128, 0.233)
HL-H score: 910.439 (725.654, 1174.481)
HL-H p-value: 0. (0., 0.)
ECE-C topclass: 0.074 (0.066, 0.085)
ECE-C: 0.075 (0.066, 0.086)
MCE-C topclass: 0.141 (0.128, 0.182)
MCE-C: 0.140 (0.117, 0.182)
HL-C score: 2246.171 (1484.448, 3735.649)
HL-C p-value: 0. (0., 0.)
COX coef: 0.507 (0.479, 0.536)
COX intercept: 0.000 (-0.076, 0.083)
COX coef lowerci: 0.478 (0.451, 0.506)
COX coef upperci: 0.536 (0.506, 0.566)
COX intercept lowerci: -0.078 (-0.155, 0.005)
COX intercept upperci: 0.079 (0.003, 0.161)
COX ICI: 0.077 (0.070, 0.085)
Loess ICI: 0.07 (0.063, 0.079)
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=702\sphinxpxdimen,height=545\sphinxpxdimen]{{notebooks_quickstart_19_5}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxstepscope


\chapter{Summary and guide for calibration metrics}
\label{\detokenize{notebooks/metrics_summary:Summary-and-guide-for-calibration-metrics}}\label{\detokenize{notebooks/metrics_summary::doc}}
\sphinxAtStartPar
We provide a summary of the calibration metrics provides by calzone, including the pros and cons of each metrics. For a more detailed explanation of each metrics and how to calculate them using calzone, please refer to the specific notebook.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[4]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{display}\PYG{p}{(}\PYG{n}{HTML}\PYG{p}{(}\PYG{n}{styled\PYGZus{}df}\PYG{o}{.}\PYG{n}{to\PYGZus{}html}\PYG{p}{(}\PYG{n}{escape}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Guide to Calibration Metrics}
\label{\detokenize{notebooks/metrics_summary:Guide-to-Calibration-Metrics}}
\sphinxAtStartPar
We recommend visualizing calibration using reliability diagrams. If you observe general over\sphinxhyphen{} or under\sphinxhyphen{}estimation of probabilities for a given class, consider applying a prevalence adjustment to determine if it’s solely due to prevalence shift. After prevalence adjustment, plot the reliability diagrams again and examine the results of calibration metrics.

\sphinxAtStartPar
For a general sense of average probability deviation, we recommend using the Cox and Loess integrated calibration index (ICI). To test for calibration, we suggest using Spiegelhalter’s z\sphinxhyphen{}test. Other metrics such as Expected Calibration Error (ECE), Cox slope/intercept, and Hosmer\sphinxhyphen{}Lemeshow (HL) test depends strongly on binning and should be used with caution.

\sphinxAtStartPar
Please refer to the following sections for detailed descriptions of each metric.

\sphinxstepscope


\chapter{Reliability diagram}
\label{\detokenize{notebooks/reliability_diagram:Reliability-diagram}}\label{\detokenize{notebooks/reliability_diagram::doc}}
\sphinxAtStartPar
Reliability Diagram is a tool to visualize the calibration of a model given a set of data. It groups the data into bins and plots the accuracy of each bin against the average predicted value for that bin. The reliability diagram can be plotted for top\sphinxhyphen{}class prediction only or for a given class. The calzone package provides a function to calculate and plot the reliability diagram.

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[1]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Import the necessary libraries and load the data}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{,}\PYG{n}{data\PYGZus{}loader}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{vis} \PYG{k+kn}{import} \PYG{n}{plot\PYGZus{}reliability\PYGZus{}diagram}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} loading the data}
\PYG{n}{wellcal\PYGZus{}dataloader} \PYG{o}{=} \PYG{n}{data\PYGZus{}loader}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[13]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Create and plot the top\PYGZhy{}class well calibrated data}
\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}clasto plot is None mean calcuate for top\PYGZhy{}class}
\PYG{c+c1}{\PYGZsh{} Plot the reliability diagram}
\PYG{n}{plot\PYGZus{}reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts}\PYG{p}{,}\PYG{n}{error\PYGZus{}bar}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}\PYG{n}{title}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Top class reliability diagram for well calibrated data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=702\sphinxpxdimen,height=545\sphinxpxdimen]{{notebooks_reliability_diagram_3_0}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
The error bar in the reliability diagram is the 95\% confidence interval calculated using wilson score interval which assume that samples in a bin is a series of Bernoulli trials with the success probability equal to the mean predicted probability. The confidence interval is only for reference and might not be exact.

\sphinxAtStartPar
Since we have a binary classification problem, The mean predicted probability will not go below 0.5 for top\sphinxhyphen{}class reliability diagram. We will proceed to plot the class 1 reliability diagram.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[14]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Create and plot the class 1 well calibrated data}
\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Plot the reliability diagram}
\PYG{n}{plot\PYGZus{}reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts}\PYG{p}{,}\PYG{n}{error\PYGZus{}bar}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}\PYG{n}{title}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Class 1 reliability diagram for well calibrated data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=702\sphinxpxdimen,height=545\sphinxpxdimen]{{notebooks_reliability_diagram_5_0}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Class\sphinxhyphen{}by\sphinxhyphen{}class reliability diagram reveal more information about the model’s calibbration. The top\sphinxhyphen{}class reliability diagram could be misleading as it could shows reasonable calibration for the top\sphinxhyphen{}class, but the model could be overconfident for the other classes. We can demonstrate in the following example.

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[40]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} We will artificially drop the prevalence of class 1}
\PYG{c+c1}{\PYGZsh{} The top\PYGZhy{}class reliability diagram will still look good}
\PYG{c+c1}{\PYGZsh{} But the class\PYGZhy{}1 reliability diagram will be very bad}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{softmax\PYGZus{}to\PYGZus{}logits}
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{special} \PYG{k+kn}{import} \PYG{n}{softmax}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}

\PYG{n}{test\PYGZus{}dataloader} \PYG{o}{=} \PYG{n}{data\PYGZus{}loader}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{class\PYGZus{}1\PYGZus{}index} \PYG{o}{=} \PYG{p}{(}\PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{o}{==}\PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} We will drop 50\PYGZpc{} of class 1 samples}
\PYG{n}{class\PYGZus{}1\PYGZus{}samples} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n}{class\PYGZus{}1\PYGZus{}index}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n}{drop\PYGZus{}indices} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{choice}\PYG{p}{(}\PYG{n}{class\PYGZus{}1\PYGZus{}samples}\PYG{p}{,} \PYG{n}{size}\PYG{o}{=}\PYG{n+nb}{int}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{class\PYGZus{}1\PYGZus{}samples}\PYG{p}{)}\PYG{o}{/}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{,} \PYG{n}{replace}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

\PYG{n}{mask} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dtype}\PYG{o}{=}\PYG{n+nb}{bool}\PYG{p}{)}
\PYG{n}{mask}\PYG{p}{[}\PYG{n}{drop\PYGZus{}indices}\PYG{p}{]} \PYG{o}{=} \PYG{k+kc}{False}

\PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels} \PYG{o}{=} \PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{[}\PYG{n}{mask}\PYG{p}{]}
\PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs} \PYG{o}{=} \PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{[}\PYG{n}{mask}\PYG{p}{]}
\PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{data} \PYG{o}{=} \PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{mask}\PYG{p}{]}

\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[42]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Create and plot the top\PYGZhy{}class reliability diagram}
\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)}
\PYG{n}{plot\PYGZus{}reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts}\PYG{p}{,}\PYG{n}{error\PYGZus{}bar}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}\PYG{n}{title}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Top class reliability diagram for mis calibrated data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=702\sphinxpxdimen,height=545\sphinxpxdimen]{{notebooks_reliability_diagram_8_0}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[43]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Create and plot the class\PYGZhy{}by\PYGZhy{}class reliability diagram}
\PYG{n}{reliability\PYGZus{}0}\PYG{p}{,}\PYG{n}{confindence\PYGZus{}0}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts\PYGZus{}0} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)}
\PYG{n}{reliability\PYGZus{}1}\PYG{p}{,}\PYG{n}{confindence\PYGZus{}1}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts\PYGZus{}1} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{test\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{reliability} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{vstack}\PYG{p}{(}\PYG{p}{(}\PYG{n}{reliability\PYGZus{}0}\PYG{p}{,}\PYG{n}{reliability\PYGZus{}1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{confindence} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{vstack}\PYG{p}{(}\PYG{p}{(}\PYG{n}{confindence\PYGZus{}0}\PYG{p}{,}\PYG{n}{confindence\PYGZus{}1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{vstack}\PYG{p}{(}\PYG{p}{(}\PYG{n}{bin\PYGZus{}counts\PYGZus{}0}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts\PYGZus{}1}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{plot\PYGZus{}reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts}\PYG{p}{,}\PYG{n}{error\PYGZus{}bar}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}\PYG{n}{title}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{class\PYGZhy{}by\PYGZhy{}class reliability diagram for mis calibrated data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{custom\PYGZus{}colors}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{blue}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{red}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=702\sphinxpxdimen,height=545\sphinxpxdimen]{{notebooks_reliability_diagram_9_0}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
The example shows us that the prevalence shift in the testing data could lead to mis\sphinxhyphen{}calibration in a posterior sense. The calzone provide a method to calibrate it. The prevalence is not related to the model and the model could still have the correct likelihood ratio. See more discussion in the prevalence adjustment section.

\sphinxstepscope


\chapter{Exepected Calibration Error(ECE) and Maximum Calibration Error (MCE)}
\label{\detokenize{notebooks/ece_mce:Exepected-Calibration-Error(ECE)-and-Maximum-Calibration-Error-(MCE)}}\label{\detokenize{notebooks/ece_mce::doc}}

\section{Theoretical Background}
\label{\detokenize{notebooks/ece_mce:Theoretical-Background}}
\sphinxAtStartPar
(True) Expected Calibration Error is defined as the average difference between the predicted probability and the true probability for a particular class. We will label the predicted probability as \(\hat{P}\) and the true probability as \(P\) and drop the class of interest label for simplicity.
\begin{equation*}
\begin{split}\text{ECE} = \mathbb{E}_{\hat{P}} [|\mathbb{P}(\hat{Y}=Y|\hat{P}=p)-p|] = \int_0^1 |\mathbb{P}(\hat{Y}=Y|\hat{P}=p)-p| \, dF_{\hat{P}}(p)\end{split}
\end{equation*}
\sphinxAtStartPar
Some also define the ECE as the average difference between the predicted probability and the true probability of the predicted class. This is similar to the top\sphinxhyphen{}class vs class\sphinxhyphen{}by\sphinxhyphen{}class reliability diagram. We will refer to it as \(\text{ECE}_{top}\).
\begin{equation*}
\begin{split}\text{ECE}_{top} = \mathbb{E}_{\hat{P_{top}}} [|\mathbb{P}(\hat{Y_{top}}=Y_{top}|\hat{P_{top}}=p_{top})-p_{top}|])\end{split}
\end{equation*}
\sphinxAtStartPar
Similarly, we can also define the Maximum Calibration Error (MCE) as the maximum difference between the predicted and true probabilities:
\begin{equation*}
\begin{split}\text{MCE} = \max_p |\mathbb{P}(\hat{Y}=Y|\hat{P}=p)-p|\end{split}
\end{equation*}\begin{equation*}
\begin{split}\text{MCE}_{top} = \max_{p_{top}}|\mathbb{P}(\hat{Y_{top}}=Y_{top}|\hat{P}=p_{top})-p_{top}|\end{split}
\end{equation*}

\subsection{Estimated ECE and MCE}
\label{\detokenize{notebooks/ece_mce:Estimated-ECE-and-MCE}}
\sphinxAtStartPar
We can’t compute ECE and MCE directly from the data. Alternatively, we can group the data into bins and compute an Estimated ECE and MCE from the grouped data. In most literature, the estimated ECE and MCE are simply referred to as ECE and MCE. We adopt the same convention but want to remind the reader that the estimated ECE and MCE are not the same as the true ECE and MCE and they heavily depend on the binning method. In the text below, we will use the terms ECE and MCE to refer to the
estimated ECE and MCE, and true ECE and MCE to refer to the true ECE and MCE.
\begin{equation*}
\begin{split}\text{ECE}  = \sum_{m=1}^M \frac{|B_m|}{n} |acc(B_m) - conf(B_m)|\end{split}
\end{equation*}
\sphinxAtStartPar
where M is the number of bins, \(B_m\) is the m\sphinxhyphen{}th bin, \(acc(B_m)\) is the accuracy of the m\sphinxhyphen{}th bin, \(conf(B_m)\) is the mean predicted probability of the m\sphinxhyphen{}th bin, and \(n\) is the total number of samples. The ECE\sphinxhyphen{}topclass is a simple extension where only the top\sphinxhyphen{}class probability is used to group the data. We can define MCE similarly.
\begin{equation*}
\begin{split}\text{MCE}  = \max_m |acc(B_m) - conf(B_m)|\end{split}
\end{equation*}
\sphinxAtStartPar
Both ECE and MCE group the data based on the predicted probability. This means the resulting ECE and MCE depend on the binning method used. Traditionally, the data are grouped into 10 equal\sphinxhyphen{}width bins. However, if the data is not evenly distributed, the resulting ECE and MCE may not be a good representation of the model’s calibration.

\sphinxAtStartPar
Nixon et al. (2019) proposed a new binning method which bins the data into equal\sphinxhyphen{}count bins. They refer to the resulting ECE as Adaptive Calibration Error (ACE). The ACE also accounts for all the predictions for all classes. This is equivalent to a sum of ECE for all classes.

\sphinxAtStartPar
We will adopt a modified version of the ACE and aim to measure the true ECE with equal\sphinxhyphen{}count binning but ignore the part about summing over all classes. This is equivalent to the ECE but only with equal\sphinxhyphen{}count binning. We will refer to the equal\sphinxhyphen{}width binning ECE as ECE\sphinxhyphen{}H and the equal\sphinxhyphen{}count binning ECE as ECE\sphinxhyphen{}C. Similarly, we will refer to the equal\sphinxhyphen{}width binning MCE as MCE\sphinxhyphen{}H and the equal\sphinxhyphen{}count binning MCE as MCE\sphinxhyphen{}C.


\section{Pros of ECE and MCE}
\label{\detokenize{notebooks/ece_mce:Pros-of-ECE-and-MCE}}
\sphinxAtStartPar
ECE and MCE are perhaps the most intuitive metrics for measuring the calibration of a probabilistic model. They are simply the average deviation of the predicted probability from the true probability and the maximum deviation of the predicted probability from the true probability. The ECE and MCE are also easy to compute and interpret. ECE could be computed by doing a weighted average of the reliability diagram based on bin counts and MCE is just the maximum difference between the accuracy and
the confidence. Because of that, ECE and MCE are widely used in the machine learning literature.


\section{Cons of ECE and MCE}
\label{\detokenize{notebooks/ece_mce:Cons-of-ECE-and-MCE}}
\sphinxAtStartPar
The biggest disadvantage of using ECE and MCE is that they rely on the binning scheme, and results will depend on the binning scheme and the number of bins. It can be shown that the average ECE and MCE will always increase with the number of bins and the average ECE and MCE will change with the number of samples for a fixed number of bins. This causes problems when interpreting the results. We will do a simple experiment in the following section to show this. Because of the above reasons, we
recommend using ECE and MCE with other metrics that are not dependent on the binning scheme.


\section{Calculating ECE and MCE with calzone}
\label{\detokenize{notebooks/ece_mce:Calculating-ECE-and-MCE-with-calzone}}
\sphinxAtStartPar
There is two way to calculate the ECE and MCE in calzone. The first way is by calling the function explicitly.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[2]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{,}\PYG{n}{data\PYGZus{}loader}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{calculate\PYGZus{}ece\PYGZus{}mce}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} loading the data}
\PYG{n}{wellcal\PYGZus{}dataloader} \PYG{o}{=} \PYG{n}{data\PYGZus{}loader}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} calculating the top\PYGZhy{}class ECE\PYGZhy{}H}
\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{is\PYGZus{}equal\PYGZus{}freq}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{ece\PYGZus{}h\PYGZus{}top\PYGZus{}class}\PYG{p}{,}\PYG{n}{mce\PYGZus{}h\PYGZus{}top\PYGZus{}class} \PYG{o}{=} \PYG{n}{calculate\PYGZus{}ece\PYGZus{}mce}\PYG{p}{(}\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts}\PYG{o}{=}\PYG{n}{bin\PYGZus{}counts}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Top\PYGZhy{}class ECE\PYGZhy{}H: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{ece\PYGZus{}h\PYGZus{}top\PYGZus{}class}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Top\PYGZhy{}class MCE\PYGZhy{}H: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{mce\PYGZus{}h\PYGZus{}top\PYGZus{}class}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Top-class ECE-H:  0.009608653731328977
Top-class MCE-H:  0.03926468843081976
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[3]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} We can calculate the class 1 ECE and MCE by setting class\PYGZus{}to\PYGZus{}plot=1}
\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{is\PYGZus{}equal\PYGZus{}freq}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{ece\PYGZus{}h\PYGZus{}classone}\PYG{p}{,}\PYG{n}{mce\PYGZus{}h\PYGZus{}classone} \PYG{o}{=} \PYG{n}{calculate\PYGZus{}ece\PYGZus{}mce}\PYG{p}{(}\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts}\PYG{o}{=}\PYG{n}{bin\PYGZus{}counts}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Class 1 ECE\PYGZhy{}H: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{ece\PYGZus{}h\PYGZus{}classone}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Class 1 MCE\PYGZhy{}H: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{mce\PYGZus{}h\PYGZus{}classone}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Class 1 ECE-H:  0.01208775955804901
Class 1 MCE-H:  0.04848338618970194
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[4]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Similarily we can calculate the class 1 ECE\PYGZhy{}C and top\PYGZhy{}class ECE\PYGZhy{}C by setting is\PYGZus{}equal\PYGZus{}freq=True}
\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{is\PYGZus{}equal\PYGZus{}freq}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{ece\PYGZus{}c\PYGZus{}top\PYGZus{}class}\PYG{p}{,}\PYG{n}{mce\PYGZus{}c\PYGZus{}top\PYGZus{}class} \PYG{o}{=} \PYG{n}{calculate\PYGZus{}ece\PYGZus{}mce}\PYG{p}{(}\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts}\PYG{o}{=}\PYG{n}{bin\PYGZus{}counts}\PYG{p}{)}
\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{is\PYGZus{}equal\PYGZus{}freq}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{ece\PYGZus{}c\PYGZus{}classone}\PYG{p}{,}\PYG{n}{mce\PYGZus{}c\PYGZus{}classone} \PYG{o}{=} \PYG{n}{calculate\PYGZus{}ece\PYGZus{}mce}\PYG{p}{(}\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts}\PYG{o}{=}\PYG{n}{bin\PYGZus{}counts}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Top\PYGZhy{}class ECE\PYGZhy{}C: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{ece\PYGZus{}c\PYGZus{}top\PYGZus{}class}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Top\PYGZhy{}class MCE\PYGZhy{}C: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{mce\PYGZus{}c\PYGZus{}top\PYGZus{}class}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Class 1 ECE\PYGZhy{}C: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{ece\PYGZus{}c\PYGZus{}classone}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Class 1 MCE\PYGZhy{}C: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{mce\PYGZus{}c\PYGZus{}classone}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Top-class ECE-C:  0.009458033653818828
Top-class MCE-C:  0.020515047600205505
Class 1 ECE-C:  0.008733966945443138
Class 1 MCE-C:  0.02324031223486256
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
The second method is much simpler. We can use the calzone.metrics.CalibrationMetrics class to calculate all type of metrics.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[7]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{CalibrationMetrics}
\PYG{n}{calmetrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{calmetrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ECE\PYGZhy{}H}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{MCE\PYGZhy{}H}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ECE\PYGZhy{}C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{MCE\PYGZhy{}C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[7]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\{'ECE-H topclass': 0.009608653731328977,
 'ECE-H': 0.01208775955804901,
 'MCE-H topclass': 0.03926468843081976,
 'MCE-H': 0.04848338618970194,
 'ECE-C topclass': 0.009458033653818828,
 'ECE-C': 0.008733966945443138,
 'MCE-C topclass': 0.020515047600205505,
 'MCE-C': 0.02324031223486256\}
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{ECE and MCE as function of bin size}
\label{\detokenize{notebooks/ece_mce:ECE-and-MCE-as-function-of-bin-size}}
\sphinxAtStartPar
In this section, we want to quickly demonstrate how binning could affect the ECE and MCE.

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[11]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{range\PYGZus{}of\PYGZus{}binning} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{300}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{result} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{range\PYGZus{}of\PYGZus{}binning}\PYG{p}{)}\PYG{p}{,}\PYG{l+m+mi}{8}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{range\PYGZus{}of\PYGZus{}binning}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{calmetrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{n}{range\PYGZus{}of\PYGZus{}binning}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{result}\PYG{p}{[}\PYG{n}{i}\PYG{p}{,}\PYG{p}{:}\PYG{p}{]} \PYG{o}{=} \PYG{n}{calmetrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ECE\PYGZhy{}H}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{MCE\PYGZhy{}H}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ECE\PYGZhy{}C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{MCE\PYGZhy{}C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{return\PYGZus{}numpy}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[12]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{range\PYGZus{}of\PYGZus{}binning}\PYG{p}{,}\PYG{n}{result}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ECE Equal Width}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{range\PYGZus{}of\PYGZus{}binning}\PYG{p}{,}\PYG{n}{result}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{]}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ECE Equal Count}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ECE vs Number of Bins (10000 samples)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}plt.ylim(0, np.max(ece\PYGZus{}equal\PYGZus{}width)+0.1)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Number of Bins}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[12]:\,\hspace{\fboxrule}\hspace{\fboxsep}}<matplotlib.legend.Legend at 0x7f0e5336cbc0>
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=556\sphinxpxdimen,height=453\sphinxpxdimen]{{notebooks_ece_mce_12_1}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
We can see that the error goes up as the number of bins increases while equal count and equal width always return different results. Opposite effects can be observed for the number of sample. Therefore, ECE and MCE can only give us a rough estimate of the calibation error of the model.


\section{Reference}
\label{\detokenize{notebooks/ece_mce:Reference}}
\sphinxAtStartPar
Guo, C., Pleiss, G., Sun, Y., \& Weinberger, K. Q. (2017). On Calibration of Modern Neural Networks (No. arXiv:1706.04599). arXiv. http://arxiv.org/abs/1706.04599

\sphinxAtStartPar
Pakdaman Naeini, M., Cooper, G., \& Hauskrecht, M. (2015). Obtaining Well Calibrated Probabilities Using Bayesian Binning. Proceedings of the AAAI Conference on Artificial Intelligence, 29(1). \sphinxurl{https://doi.org/10.1609/aaai.v29i1.9602}

\sphinxAtStartPar
Arrieta\sphinxhyphen{}Ibarra, I., Gujral, P., Tannen, J., Tygert, M., \& Xu, C. (2022). Metrics of Calibration for Probabilistic Predictions.

\sphinxAtStartPar
Nixon, J., Dusenberry, M. W., Zhang, L., Jerfel, G., \& Tran, D. (2020). Measuring Calibration in Deep Learning.

\sphinxstepscope


\chapter{Hosmer\sphinxhyphen{}Lemeshow test (HL test)}
\label{\detokenize{notebooks/hl_test:Hosmer-Lemeshow-test-(HL-test)}}\label{\detokenize{notebooks/hl_test::doc}}

\section{Theoretical Background}
\label{\detokenize{notebooks/hl_test:Theoretical-Background}}
\sphinxAtStartPar
The Hosmer\sphinxhyphen{}Lemeshow test (HL Test) is a statistical test that can be used to assess the calibration of a probabilistic model. The test works by dividing the predicted probabilities into groups (typically deciles) and comparing the observed and expected frequencies of events in each group. A non\sphinxhyphen{}significant p\sphinxhyphen{}value (usually greater than 0.05) indicates we cannot reject the hypothesis that the model is well\sphinxhyphen{}calibrated, while a significant p\sphinxhyphen{}value suggests the opposite. The Hosmer\sphinxhyphen{}Lemeshow test is
widely used in the literature and industry since it is simple to implement and interpret.

\sphinxAtStartPar
In order to calculate the Hosmer\sphinxhyphen{}Lemeshow test statistic, we need to first determine the binning scheme used to divide the predicted probabilities into groups. Conventionally, the predicted probabilities are divided into 10 equal\sphinxhyphen{}width bins. We will label the equal\sphinxhyphen{}width binning Hosmer\sphinxhyphen{}Lemeshow test as HL\sphinxhyphen{}H and equal\sphinxhyphen{}count binning Hosmer\sphinxhyphen{}Lemeshow test as HL\sphinxhyphen{}C. The Hosmer\sphinxhyphen{}Lemeshow test statistic is then calculated as follows:
\begin{equation*}
\begin{split}\text{HL} = \sum_{m=1}^{M} \left[\frac{(O_{1,m}-E_{1,m})^2}{E_{1,m}} + \frac{(O_{0,m}-E_{0,m})^2}{E_{0,m}}\right]  = \sum_{m=1}^{M} \frac{(O_{1,m}-E_{1,m})^2}{E_{1,m}(1-\frac{E_{1,m}}{N_m})} \sim \chi^2_{M-2}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(E_{1,m}\) is the expected number of class 1 events in the \(\text{m}^{th}\) bin, \(O_{1,m}\) is the observed number of class 1 events in the \(\text{m}^{th}\) bin, \(N_m\) is the total number of observations in the \(\text{m}^{th}\) bin, and \(M\) is the number of bins. The HL test statistic is distributed as a chi\sphinxhyphen{}squared distribution with \(M-2\) degrees of freedom. We can then use this test statistic to calculate the p\sphinxhyphen{}value for the test and determine
whether we can reject the null hypothesis that the model is well\sphinxhyphen{}calibrated.


\section{Pros of HL test}
\label{\detokenize{notebooks/hl_test:Pros-of-HL-test}}
\sphinxAtStartPar
The Hosmer\sphinxhyphen{}Lemeshow test offers several advantages in assessing calibration. It is a non\sphinxhyphen{}parametric test, meaning it does not require any assumptions about the distribution of the predicted probabilities, and it provides statistical meaning to the resulting test statistic. It is also very intuitive and easy to understand since it is just a chi\sphinxhyphen{}square based test. It can be calculated from the result of the reliability diagram. The HL test is widely used in the literature as a validation method
for model calibration.


\section{Cons of HL Test}
\label{\detokenize{notebooks/hl_test:Cons-of-HL-Test}}
\sphinxAtStartPar
Many studies have shown that the HL test is not an ideal way to examine the calibration of a model. The biggest problem is that the HL test depends on the binning scheme used. Whether equal\sphinxhyphen{}width or equal\sphinxhyphen{}count binning and the number of bins used can affect the results of the HL test. It is shown that the standard 10 equal\sphinxhyphen{}width bins often have the wrong size and low statistical power. Therefore, it is recommended not to use the HL test to examine the calibration of a model. However, the HL test
is still a useful tool to quickly check the calibration of a model and provide a reference for the calibration of a model.


\section{Calculating HL test statistics and p\sphinxhyphen{}value with calzone}
\label{\detokenize{notebooks/hl_test:Calculating-HL-test-statistics-and-p-value-with-calzone}}
\sphinxAtStartPar
There are again two ways to calculate the HL test statistics and p\sphinxhyphen{}value with calzone. One is to call the function explicitly, and the other is to use the calzone.metrics.CalibrationMetrics class.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[1]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{,}\PYG{n}{data\PYGZus{}loader}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{hosmer\PYGZus{}lemeshow\PYGZus{}test}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} loading the data}
\PYG{n}{wellcal\PYGZus{}dataloader} \PYG{o}{=} \PYG{n}{data\PYGZus{}loader}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} calculating the HL\PYGZhy{}H TS}
\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{is\PYGZus{}equal\PYGZus{}freq}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

\PYG{n}{HL\PYGZus{}H\PYGZus{}ts}\PYG{p}{,}\PYG{n}{HL\PYGZus{}H\PYGZus{}p}\PYG{p}{,}\PYG{n}{df} \PYG{o}{=} \PYG{n}{hosmer\PYGZus{}lemeshow\PYGZus{}test}\PYG{p}{(}\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}count}\PYG{o}{=}\PYG{n}{bin\PYGZus{}counts}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{HL\PYGZhy{}H Test Statistic: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{HL\PYGZus{}H\PYGZus{}ts}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{HL\PYGZhy{}H p\PYGZhy{}value: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{HL\PYGZus{}H\PYGZus{}p}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
HL-H Test Statistic:  8.884991559088098
HL-H p-value:  0.35209071874348785
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[2]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} similar for HL\PYGZhy{}C model}
\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{is\PYGZus{}equal\PYGZus{}freq}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{n}{HL\PYGZus{}C\PYGZus{}ts}\PYG{p}{,}\PYG{n}{HL\PYGZus{}C\PYGZus{}p}\PYG{p}{,}\PYG{n}{df} \PYG{o}{=} \PYG{n}{hosmer\PYGZus{}lemeshow\PYGZus{}test}\PYG{p}{(}\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}count}\PYG{o}{=}\PYG{n}{bin\PYGZus{}counts}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{HL\PYGZhy{}C Test Statistic: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{HL\PYGZus{}C\PYGZus{}ts}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{HL\PYGZhy{}C p\PYGZhy{}value: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{HL\PYGZus{}C\PYGZus{}p}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
HL-C Test Statistic:  3.694947603203135
HL-C p-value:  0.8835446575708198
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
We can see the result from equal\sphinxhyphen{}width binning and equal\sphinxhyphen{}count binning are different. We will demostrate how to use the calzone.metrics.CalibrationMetrics class.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[3]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} using the CalibrationMetrics class}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{CalibrationMetrics}
\PYG{n}{calmetrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{calmetrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{HL\PYGZhy{}H}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{HL\PYGZhy{}C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[3]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\{'HL-H score': 8.884991559088098,
 'HL-H p-value': 0.35209071874348785,
 'HL-C score': 3.694947603203135,
 'HL-C p-value': 0.8835446575708198\}
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Size of HL test}
\label{\detokenize{notebooks/hl_test:Size-of-HL-test}}
\sphinxAtStartPar
We will show HL having the wrong size. The power of HL test will be demostrated in the Power section of the next notebook. We will need to generate fake data.

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[4]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} The size of HL Test}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{123}\PYG{p}{)}
\PYG{n}{fakedata\PYGZus{}generator} \PYG{o}{=} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}\PYG{p}{(}\PYG{n}{alpha\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{beta\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}
\PYG{n}{cal\PYGZus{}metrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{sample\PYGZus{}size} \PYG{o}{=} \PYG{l+m+mi}{1000}
\PYG{n}{simulation\PYGZus{}size} \PYG{o}{=} \PYG{l+m+mi}{10000}
\PYG{n}{results} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{} generate data}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{simulation\PYGZus{}size}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{X}\PYG{p}{,} \PYG{n}{y} \PYG{o}{=} \PYG{n}{fakedata\PYGZus{}generator}\PYG{o}{.}\PYG{n}{generate\PYGZus{}data}\PYG{p}{(}\PYG{n}{sample\PYGZus{}size}\PYG{p}{)}
    \PYG{k}{if} \PYG{n}{i} \PYG{o}{==} \PYG{l+m+mi}{0}\PYG{p}{:}
        \PYG{n}{tempresult} \PYG{o}{=} \PYG{n}{cal\PYGZus{}metrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{HL\PYGZhy{}H}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{HL\PYGZhy{}C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{return\PYGZus{}numpy}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
        \PYG{n}{keys} \PYG{o}{=} \PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{tempresult}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
        \PYG{n}{results}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{tempresult}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{n}{tempresult} \PYG{o}{=} \PYG{n}{cal\PYGZus{}metrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{HL\PYGZhy{}H}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{HL\PYGZhy{}C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{return\PYGZus{}numpy}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
        \PYG{n}{results}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{tempresult}\PYG{p}{)}
\PYG{n}{results} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{results}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[5]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Showing the size of the model}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{n}{hl\PYGZus{}h\PYGZus{}pvalue} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{n}{hl\PYGZus{}c\PYGZus{}pvalue} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{]}
\PYG{n}{size\PYGZus{}h} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{hl\PYGZus{}h\PYGZus{}pvalue} \PYG{o}{\PYGZlt{}} \PYG{l+m+mf}{0.05}\PYG{p}{)}
\PYG{n}{size\PYGZus{}c} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{hl\PYGZus{}c\PYGZus{}pvalue} \PYG{o}{\PYGZlt{}} \PYG{l+m+mf}{0.05}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The size of HL\PYGZhy{}H is :}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{round}\PYG{p}{(}\PYG{n}{size\PYGZus{}h}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The size of HL\PYGZhy{}C is :}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{round}\PYG{p}{(}\PYG{n}{size\PYGZus{}c}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
The size of HL-H is : 0.117
The size of HL-C is : 0.116
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[6]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{value}\PYG{p}{,}\PYG{n}{\PYGZus{}}\PYG{p}{,}\PYG{n}{\PYGZus{}}\PYG{o}{=}\PYG{n}{plt}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{hl\PYGZus{}h\PYGZus{}pvalue}\PYG{p}{,} \PYG{n}{bins}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{density}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Equal\PYGZhy{}width binning}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{histtype}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{step}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{vlines}\PYG{p}{(}\PYG{n}{size\PYGZus{}h}\PYG{p}{,}\PYG{n}{ymin}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{ymax}\PYG{o}{=}\PYG{n}{np}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{n}{value}\PYG{p}{)}\PYG{p}{,}\PYG{n}{linestyle}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+sa}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Size of equal\PYGZhy{}width bin (\PYGZdl{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{alpha=0.05\PYGZdl{}) = }\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{+}\PYG{n+nb}{str}\PYG{p}{(}\PYG{n+nb}{round}\PYG{p}{(}\PYG{n}{size\PYGZus{}h}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}\PYG{n}{colors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{n}{loc}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{upper right}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{p\PYGZhy{}value}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Density}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{P\PYGZhy{}value distribution of the HL test}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[6]:\,\hspace{\fboxrule}\hspace{\fboxsep}}Text(0.5, 1.0, 'P-value distribution of the HL test')
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=567\sphinxpxdimen,height=453\sphinxpxdimen]{{notebooks_hl_test_13_1}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[7]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{value}\PYG{p}{,}\PYG{n}{\PYGZus{}}\PYG{p}{,}\PYG{n}{\PYGZus{}}\PYG{o}{=}\PYG{n}{plt}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{hl\PYGZus{}c\PYGZus{}pvalue}\PYG{p}{,} \PYG{n}{bins}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{density}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Equal\PYGZhy{}count binning}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{histtype}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{step}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{vlines}\PYG{p}{(}\PYG{n}{size\PYGZus{}c}\PYG{p}{,}\PYG{n}{ymin}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{ymax}\PYG{o}{=}\PYG{n}{np}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{n}{value}\PYG{p}{)}\PYG{p}{,}\PYG{n}{linestyle}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+sa}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Size of equal\PYGZhy{}count bin (\PYGZdl{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{alpha=0.05\PYGZdl{}) = }\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{+}\PYG{n+nb}{str}\PYG{p}{(}\PYG{n+nb}{round}\PYG{p}{(}\PYG{n}{size\PYGZus{}c}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}\PYG{n}{colors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{n}{loc}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{upper right}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{p\PYGZhy{}value}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Density}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{P\PYGZhy{}value distribution of the HL test}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[7]:\,\hspace{\fboxrule}\hspace{\fboxsep}}Text(0.5, 1.0, 'P-value distribution of the HL test')
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=567\sphinxpxdimen,height=453\sphinxpxdimen]{{notebooks_hl_test_14_1}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
We can see that both the equal\sphinxhyphen{}width and the equal\sphinxhyphen{}count method have the incorrect size.


\section{Reference}
\label{\detokenize{notebooks/hl_test:Reference}}
\sphinxAtStartPar
Hosmer, D. W., \& Lemesbow, S. (1980). Goodness of fit tests for the multiple logistic regression model. Communications in statistics\sphinxhyphen{}Theory and Methods, 9(10), 1043\sphinxhyphen{}1069.

\sphinxAtStartPar
Hosmer, D. W., Hosmer, T., Cessie, S. L., \& Lemeshow, S. (1997). A COMPARISON OF GOODNESS\sphinxhyphen{}OF\sphinxhyphen{}FIT TESTS FOR THE LOGISTIC REGRESSION MODEL. 16.

\sphinxstepscope


\chapter{COX calibration analysis}
\label{\detokenize{notebooks/cox:COX-calibration-analysis}}\label{\detokenize{notebooks/cox::doc}}

\section{Theoretical Background}
\label{\detokenize{notebooks/cox:Theoretical-Background}}
\sphinxAtStartPar
Cox calibration analysis is both a logistic recalibration technique and a method to examine the current calibration of a model. To perform the analysis, we first need to fit a new logistic regression model using logit (log odds, aka \(\log\frac{\hat{p}}{1-\hat{p}}\)) as the predictor variable and the outcome as the target variable.
\begin{equation*}
\begin{split}p_{new} = \frac{1}{1+e^{-(a + b \cdot \log\frac{\hat{p}}{1-\hat{p}})}}\end{split}
\end{equation*}
\sphinxAtStartPar
In the case of perfect calibration, \(P(Y=1|p=\hat{p}) = \hat{p}\) and the new probability \(p_{new}\) is equal to the original probability \(\hat{p}\). That means \(a=0\) and \(b=1\). If \(b>1\), the model is under\sphinxhyphen{}confident at high probabilities and over\sphinxhyphen{}confident at low probabilities for the class\sphinxhyphen{}of\sphinxhyphen{}interest. If \(b<1\), the model is over\sphinxhyphen{}confident at high probabilities and under\sphinxhyphen{}confident at low probabilities for the class\sphinxhyphen{}of\sphinxhyphen{}interest. If \(a>0\), the model
is over\sphinxhyphen{}confident at all probabilities for the class\sphinxhyphen{}of\sphinxhyphen{}interest. If \(a<0\), the model is under\sphinxhyphen{}confident at all probabilities for the class\sphinxhyphen{}of\sphinxhyphen{}interest. The confidence interval of \(a\) and \(b\) can be used to guide the calibration of the model. The user can also choose to fix \(a=0\) and fit for \(b\) only and vice versa, then there will be no interaction between \(a\) and \(b\) and the confidence interval can be used as a statistical test to test for perfect
calibration.


\section{Pros of Cox calibration analysis}
\label{\detokenize{notebooks/cox:Pros-of-Cox-calibration-analysis}}
\sphinxAtStartPar
Cox calibration analysis doesn’t depend on binning of data, which is a big advantage since common metrics such as ECE/MCE and HL test all depend on binning and we have shown that changing binning can lead to different results. We can also use it to perform statistical tests by fixing \(a\) to 0 and test whether \(b=1\) and the other way around to test for perfect calibration. Also, the fitted values of \(a\) and \(b\) can tell us how the model is miscalibrated, whether it is an
overall under\sphinxhyphen{} or over\sphinxhyphen{}confidence or if it is over\sphinxhyphen{}confident in some ranges and under\sphinxhyphen{}confident in others. For example, if \(a\) is not close to 0 while \(b\) is close to 1, it likely indicates a prevalence shift. See more details in the prevalence adjustment notebook.


\section{Cons of Cox calibration analysis}
\label{\detokenize{notebooks/cox:Cons-of-Cox-calibration-analysis}}
\sphinxAtStartPar
Cox Calibration analysis can only assess weak calibration and only captures certain types of miscalibration (general over/under\sphinxhyphen{}confidence). A model can have \(a=0\) and \(b=1\) and still be miscalibrated.


\section{Calculating Cox slope and intercept with calzone}
\label{\detokenize{notebooks/cox:Calculating-Cox-slope-and-intercept-with-calzone}}
\sphinxAtStartPar
There are two ways to calculate the Cox slope and intercept. Calling the Cox function gives you more control over the calculation, including fixing \(a=0\) or \(b=1\).

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[1]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{,}\PYG{n}{data\PYGZus{}loader}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{cox\PYGZus{}regression\PYGZus{}analysis}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} loading the data}
\PYG{n}{wellcal\PYGZus{}dataloader} \PYG{o}{=} \PYG{n}{data\PYGZus{}loader}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} calculating cox slope and intercept}
\PYG{n}{cox\PYGZus{}slope}\PYG{p}{,} \PYG{n}{cox\PYGZus{}intercept}\PYG{p}{,}\PYG{n}{cox\PYGZus{}slope\PYGZus{}ci}\PYG{p}{,}\PYG{n}{cox\PYGZus{}intercept\PYGZus{}ci} \PYG{o}{=} \PYG{n}{cox\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{n}{print\PYGZus{}results}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5000
Model:                          Logit   Df Residuals:                     4998
Method:                           MLE   Df Model:                            1
Date:                Thu, 26 Sep 2024   Pseudo R-squ.:                  0.4438
Time:                        09:40:42   Log-Likelihood:                -1927.5
converged:                       True   LL-Null:                       -3465.6
Covariance Type:            nonrobust   LLR p-value:                     0.000
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const         -0.0450      0.040     -1.123      0.262      -0.123       0.034
x1             0.9942      0.029     34.212      0.000       0.937       1.051
==============================================================================
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
You can also fix the intercept \(a=0\) by using the \sphinxcode{\sphinxupquote{fix\_intercept=True}} option. Similarly, you can fix the slope \(b=1\) by using the \sphinxcode{\sphinxupquote{fix\_slope=True}} option.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[8]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} fixing intercept and calculating cox slope}
\PYG{n}{cox\PYGZus{}slope}\PYG{p}{,} \PYG{n}{cox\PYGZus{}intercept}\PYG{p}{,}\PYG{n}{cox\PYGZus{}slope\PYGZus{}ci}\PYG{p}{,}\PYG{n}{cox\PYGZus{}intercept\PYGZus{}ci} \PYG{o}{=} \PYG{n}{cox\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{fix\PYGZus{}intercept}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}\PYG{n}{print\PYGZus{}results}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Warning: Maximum number of iterations has been exceeded.
         Current function value: 0.385628
         Iterations: 0
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5000
Model:                          Logit   Df Residuals:                     4999
Method:                           MLE   Df Model:                            0
Date:                Thu, 26 Sep 2024   Pseudo R-squ.:                  0.4436
Time:                        09:51:09   Log-Likelihood:                -1928.1
converged:                      False   LL-Null:                       -3465.6
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const               0          0        nan        nan           0           0
x1             0.9939      0.029     34.210      0.000       0.937       1.051
==============================================================================

Model has been estimated subject to linear equality constraints.
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Alternatively, we can use the CalibrationMetrics class to compute the COX slope and intercept.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[9]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{CalibrationMetrics}
\PYG{n}{calmetrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{calmetrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{COX}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{print\PYGZus{}results}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5000
Model:                          Logit   Df Residuals:                     4998
Method:                           MLE   Df Model:                            1
Date:                Thu, 26 Sep 2024   Pseudo R-squ.:                  0.4438
Time:                        10:14:45   Log-Likelihood:                -1927.5
converged:                       True   LL-Null:                       -3465.6
Covariance Type:            nonrobust   LLR p-value:                     0.000
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const         -0.0450      0.040     -1.123      0.262      -0.123       0.034
x1             0.9942      0.029     34.212      0.000       0.937       1.051
==============================================================================
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[9]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\{'COX coef': 0.9942499557748269,
 'COX intercept': -0.04497652296600376,
 'COX coef lowerci': 0.9372902801721911,
 'COX coef upperci': 1.0512096313774626,
 'COX intercept lowerci': -0.12348577118577644,
 'COX intercept upperci': 0.03353272525376893,
 'COX ICI': 0.005610391483826338\}
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
The resulting COX slope and intercept can be used to calibrate the model but it is beyond the scope of this package.


\section{Size of COX slope and intecept test}
\label{\detokenize{notebooks/cox:Size-of-COX-slope-and-intecept-test}}
\sphinxAtStartPar
Although Cox calibration analysis is usually only used to estimate the overall calibration trend, the resulting estimates of the slope and intercept can also be used to test whether the model is well calibrated (moderate calibration). We will do a demostrate on the size of the slope and intercept test below

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[ ]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} The size of slope test}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{123}\PYG{p}{)}
\PYG{n}{fakedata\PYGZus{}generator} \PYG{o}{=} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}\PYG{p}{(}\PYG{n}{alpha\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{beta\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}
\PYG{n}{cal\PYGZus{}metrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{sample\PYGZus{}size} \PYG{o}{=} \PYG{l+m+mi}{1000}
\PYG{n}{simulation\PYGZus{}size} \PYG{o}{=} \PYG{l+m+mi}{1000}
\PYG{n}{results} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{} generate data}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{simulation\PYGZus{}size}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{X}\PYG{p}{,} \PYG{n}{y} \PYG{o}{=} \PYG{n}{fakedata\PYGZus{}generator}\PYG{o}{.}\PYG{n}{generate\PYGZus{}data}\PYG{p}{(}\PYG{n}{sample\PYGZus{}size}\PYG{p}{)}
    \PYG{k}{if} \PYG{n}{i} \PYG{o}{==} \PYG{l+m+mi}{0}\PYG{p}{:}
        \PYG{n}{tempresult} \PYG{o}{=} \PYG{n}{cal\PYGZus{}metrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{COX}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{return\PYGZus{}numpy}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}\PYG{n}{fix\PYGZus{}intercept}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}we need to fix the intercept to be 0}
        \PYG{n}{keys} \PYG{o}{=} \PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{tempresult}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
        \PYG{n}{results}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{tempresult}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{n}{tempresult} \PYG{o}{=} \PYG{n}{cal\PYGZus{}metrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{COX}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{return\PYGZus{}numpy}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}\PYG{n}{fix\PYGZus{}intercept}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}we need to fix the intercept to be 0}
        \PYG{n}{results}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{tempresult}\PYG{p}{)}
\PYG{n}{results} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{results}\PYG{p}{)}

\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[17]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{Cox\PYGZus{}slope} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n}{Cox\PYGZus{}slope\PYGZus{}lowerci} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{]}
\PYG{n}{Cox\PYGZus{}slope\PYGZus{}upperci} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{]}
\PYG{n}{chance} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{logical\PYGZus{}and}\PYG{p}{(}\PYG{n}{Cox\PYGZus{}slope\PYGZus{}lowerci}\PYG{o}{\PYGZlt{}}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{Cox\PYGZus{}slope\PYGZus{}upperci}\PYG{o}{\PYGZgt{}}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{The size of the Cox slope test is: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{chance}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
The size of the Cox slope test is:  0.039000000000000035
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
We can also do the intercept test:

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[ ]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} The size of intercept test}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{123}\PYG{p}{)}
\PYG{n}{fakedata\PYGZus{}generator} \PYG{o}{=} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}\PYG{p}{(}\PYG{n}{alpha\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{beta\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}
\PYG{n}{cal\PYGZus{}metrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{sample\PYGZus{}size} \PYG{o}{=} \PYG{l+m+mi}{1000}
\PYG{n}{simulation\PYGZus{}size} \PYG{o}{=} \PYG{l+m+mi}{1000}
\PYG{n}{results} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{} generate data}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{simulation\PYGZus{}size}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{X}\PYG{p}{,} \PYG{n}{y} \PYG{o}{=} \PYG{n}{fakedata\PYGZus{}generator}\PYG{o}{.}\PYG{n}{generate\PYGZus{}data}\PYG{p}{(}\PYG{n}{sample\PYGZus{}size}\PYG{p}{)}
    \PYG{k}{if} \PYG{n}{i} \PYG{o}{==} \PYG{l+m+mi}{0}\PYG{p}{:}
        \PYG{n}{tempresult} \PYG{o}{=} \PYG{n}{cal\PYGZus{}metrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{COX}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{return\PYGZus{}numpy}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}\PYG{n}{fix\PYGZus{}slope}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}we need to fix the slope to be 1}
        \PYG{n}{keys} \PYG{o}{=} \PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{tempresult}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
        \PYG{n}{results}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{tempresult}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{n}{tempresult} \PYG{o}{=} \PYG{n}{cal\PYGZus{}metrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{COX}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{return\PYGZus{}numpy}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}\PYG{n}{fix\PYGZus{}slope}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}we need to fix the slope to be 1}
        \PYG{n}{results}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{tempresult}\PYG{p}{)}
\PYG{n}{results} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{results}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[19]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{Cox\PYGZus{}intercept} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{n}{Cox\PYGZus{}intercept\PYGZus{}lowerci} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{]}
\PYG{n}{Cox\PYGZus{}intercept\PYGZus{}upperci} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{]}
\PYG{n}{chance} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{logical\PYGZus{}and}\PYG{p}{(}\PYG{n}{Cox\PYGZus{}intercept\PYGZus{}lowerci}\PYG{o}{\PYGZlt{}}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{Cox\PYGZus{}intercept\PYGZus{}upperci}\PYG{o}{\PYGZgt{}}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{The size of the Cox intercept test is: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{chance}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
The size of the Cox intercept test is:  0.05600000000000005
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Both test doesn’t have the exact size but it is closer than the HL test.


\section{References}
\label{\detokenize{notebooks/cox:References}}
\sphinxAtStartPar
Cox, D. R. (1958). Two Further Applications of a Model for Binary Regression.

\sphinxAtStartPar
Calster, B. V., \& Steyerberg, E. W. (2018). Calibration of Prognostic Risk Scores. In R. S. Kenett, N. T. Longford, W. W. Piegorsch, \& F. Ruggeri (Eds.), Wiley StatsRef: Statistics Reference Online (1st ed., pp. 1\textendash{}10). Wiley. \sphinxurl{https://doi.org/10.1002/9781118445112.stat08078}

\sphinxAtStartPar
Huang, Y., Li, W., Macheret, F., Gabriel, R. A., \& Ohno\sphinxhyphen{}Machado, L. (2020). A tutorial on calibration measurements and calibration models for clinical prediction models. Journal of the American Medical Informatics Association, 27(4), 621\textendash{}633. \sphinxurl{https://doi.org/10.1093/jamia/ocz228}

\sphinxstepscope


\chapter{Integrated Calibration Index (ICI)}
\label{\detokenize{notebooks/ici:Integrated-Calibration-Index-(ICI)}}\label{\detokenize{notebooks/ici::doc}}

\section{Theoretical Background}
\label{\detokenize{notebooks/ici:Theoretical-Background}}
\sphinxAtStartPar
Integrated Calibration Index (ICI) is essentially the same as expected calibration error (ECE) in terms of the idea. They both try to measure the average deviation of the predicted probabilities from the true probabilities. However, ECE is calculated by grouping the samples into bins and then calculating the weighted average of the deviation of the mean predicted probabilities from the empirical accuracy. ICI, on the other hand, is calculated by fitting a smooth curve using the samples itself
and therefore doesn’t require binning. However, the choice of the curve fitting method can affect the result and is arbitrary. The most common choice is locally estimated scatterplot smoothing (LOESS) (Cleveland, 1979). People also use other methods such as polynomial fitting and spline fitting. Interestingly, not many people have looked into using COX regression results to calculate ICI, which is implemented in calzone. Notice that the Cox\sphinxhyphen{}ICI can be way off from the truth if the logistic
regression is not a good fit.

\sphinxAtStartPar
The formula for ICI is:
\begin{equation*}
\begin{split}\text{ICI} = \int_0^1 |\mathbb{S}(p)-p| \, dF_{\hat{P}}(p)\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\mathbb{S}(p)\) is the fitted function and \(F_{\hat{P}}(p)\) is the cumulative distribution function of the empirical probabilities. In the actual implementation, we calculate
\begin{equation*}
\begin{split}\text{ICI} = \frac{1}{N} \sum_{i=1}^N  |\mathbb{S}(p_i)-p_i|\end{split}
\end{equation*}
\sphinxAtStartPar
where \(p_i\) is the predicted probability of the \(i\)\sphinxhyphen{}th sample.


\section{Pros of ICI}
\label{\detokenize{notebooks/ici:Pros-of-ICI}}
\sphinxAtStartPar
The main advantage of ICI is that it skips the need for binning while still giving you an easily interpretable metric. It is essentially the same as ECE and can be interpreted as the average deviation from the true probability. ICI can capture any type of miscalibration if the calibration curve is well\sphinxhyphen{}described by the fitting method.


\section{Cons of ICI}
\label{\detokenize{notebooks/ici:Cons-of-ICI}}
\sphinxAtStartPar
The main disadvantage of ICI is the need for a fitting method. Locally estimated scatterplot smoothing (LOESS) is a non\sphinxhyphen{}parametric regression method that fits a smooth line through the data. It is the most common method used in ICI. However, it still requires hyperparameters like the span (window width) which could affect the fitting result and ICI greatly.


\section{Calculating LOESS ICI and COX ICI using calzone}
\label{\detokenize{notebooks/ici:Calculating-LOESS-ICI-and-COX-ICI-using-calzone}}
\sphinxAtStartPar
To calculate LOESS ICI and COX ICI using calzone, we can call the function directly

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[2]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{,}\PYG{n}{data\PYGZus{}loader}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{cox\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{,}\PYG{n}{lowess\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{,}\PYG{n}{cal\PYGZus{}ICI\PYGZus{}cox}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} loading the data}
\PYG{n}{wellcal\PYGZus{}dataloader} \PYG{o}{=} \PYG{n}{data\PYGZus{}loader}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} calculating cox ICI}
\PYG{n}{cox\PYGZus{}slope}\PYG{p}{,} \PYG{n}{cox\PYGZus{}intercept}\PYG{p}{,}\PYG{n}{cox\PYGZus{}slope\PYGZus{}ci}\PYG{p}{,}\PYG{n}{cox\PYGZus{}intercept\PYGZus{}ci} \PYG{o}{=} \PYG{n}{cox\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{n}{print\PYGZus{}results}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{cox\PYGZus{}ici} \PYG{o}{=} \PYG{n}{cal\PYGZus{}ICI\PYGZus{}cox}\PYG{p}{(}\PYG{n}{cox\PYGZus{}slope}\PYG{p}{,} \PYG{n}{cox\PYGZus{}intercept}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} calculating loess ICI}
\PYG{n}{loess\PYGZus{}ici}\PYG{p}{,} \PYG{n}{lowess\PYGZus{}fit\PYGZus{}p}\PYG{p}{,} \PYG{n}{lowess\PYGZus{}fit\PYGZus{}p\PYGZus{}correct} \PYG{o}{=} \PYG{n}{lowess\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{span}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{delta}\PYG{o}{=}\PYG{l+m+mf}{0.001}\PYG{p}{,} \PYG{n}{it}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cox ICI: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{cox\PYGZus{}ici}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Loess ICI: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{loess\PYGZus{}ici}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Cox ICI: 0.005610391483826338
Loess ICI: 0.00558856942568957
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Alternatively, we can use the CalibrationMetrics class to compute the COX and Loess ICI

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[4]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{CalibrationMetrics}
\PYG{n}{calmetrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{calmetrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{COX}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Loess}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[4]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\{'COX coef': 0.9942499557748269,
 'COX intercept': -0.04497652296600376,
 'COX coef lowerci': 0.9372902801721911,
 'COX coef upperci': 1.0512096313774626,
 'COX intercept lowerci': -0.12348577118577644,
 'COX intercept upperci': 0.03353272525376893,
 'COX ICI': 0.005610391483826338,
 'Loess ICI': 0.00558856942568957\}
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Visualization of the fitted curve}
\label{\detokenize{notebooks/ici:Visualization-of-the-fitted-curve}}
\sphinxAtStartPar
We can also plot the loess curve and the COX curve.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[10]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} We will use linear miscalibrated data to demostrate the plot. Notice that the COX should capture the miscalibration perfectly in the example case.}
\PYG{n}{miscal\PYGZus{}dataloader} \PYG{o}{=} \PYG{n}{data\PYGZus{}loader}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../../../example\PYGZus{}data/simulated\PYGZus{}misdata.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} calculating cox ICI}
\PYG{n}{cox\PYGZus{}slope}\PYG{p}{,} \PYG{n}{cox\PYGZus{}intercept}\PYG{p}{,}\PYG{n}{cox\PYGZus{}slope\PYGZus{}ci}\PYG{p}{,}\PYG{n}{cox\PYGZus{}intercept\PYGZus{}ci} \PYG{o}{=} \PYG{n}{cox\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{(}\PYG{n}{miscal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{miscal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{n}{print\PYGZus{}results}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{cox\PYGZus{}ici} \PYG{o}{=} \PYG{n}{cal\PYGZus{}ICI\PYGZus{}cox}\PYG{p}{(}\PYG{n}{cox\PYGZus{}slope}\PYG{p}{,} \PYG{n}{cox\PYGZus{}intercept}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} calculating loess ICI}
\PYG{n}{loess\PYGZus{}ici}\PYG{p}{,} \PYG{n}{lowess\PYGZus{}fit\PYGZus{}p}\PYG{p}{,} \PYG{n}{lowess\PYGZus{}fit\PYGZus{}p\PYGZus{}correct} \PYG{o}{=} \PYG{n}{lowess\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{(}\PYG{n}{miscal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{miscal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} We also try a different span}
\PYG{n}{loess\PYGZus{}ici2}\PYG{p}{,} \PYG{n}{lowess\PYGZus{}fit\PYGZus{}p2}\PYG{p}{,} \PYG{n}{lowess\PYGZus{}fit\PYGZus{}p2\PYGZus{}correct} \PYG{o}{=} \PYG{n}{lowess\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{(}\PYG{n}{miscal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{miscal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{span}\PYG{o}{=}\PYG{l+m+mf}{0.3}\PYG{p}{,} \PYG{n}{delta}\PYG{o}{=}\PYG{l+m+mf}{0.001}\PYG{p}{,} \PYG{n}{it}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cox ICI: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{cox\PYGZus{}ici}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Loess ICI (span = 0.5): }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{loess\PYGZus{}ici}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Loess ICI (span = 0.3): }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{loess\PYGZus{}ici2}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Cox ICI:  0.09541232260561425
Loess ICI (span = 0.5):  0.06991428582761099
Loess ICI (span = 0.3):  0.07263215792718729
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[29]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} ploting the curve}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{logit\PYGZus{}func}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{reliability\PYGZus{}diagram}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{vis} \PYG{k+kn}{import} \PYG{n}{plot\PYGZus{}reliability\PYGZus{}diagram}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{cox\PYGZus{}func}\PYG{o}{=} \PYG{n}{logit\PYGZus{}func}\PYG{p}{(}\PYG{n}{coef}\PYG{o}{=}\PYG{n}{cox\PYGZus{}slope}\PYG{p}{,} \PYG{n}{intercept}\PYG{o}{=}\PYG{n}{cox\PYGZus{}intercept}\PYG{p}{)}
\PYG{n}{proba\PYGZus{}class1} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sort}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{clip}\PYG{p}{(}\PYG{n}{miscal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}\PYG{l+m+mf}{1e\PYGZhy{}10}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1e\PYGZhy{}10}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{cox\PYGZus{}p\PYGZus{}correct}\PYG{o}{=}\PYG{n}{cox\PYGZus{}func}\PYG{p}{(}\PYG{n}{proba\PYGZus{}class1}\PYG{p}{)}
\PYG{n}{reliability}\PYG{p}{,}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{bin\PYGZus{}edges}\PYG{p}{,}\PYG{n}{bin\PYGZus{}counts} \PYG{o}{=} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{(}\PYG{n}{miscal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{miscal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{num\PYGZus{}bins}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{n}{confindence}\PYG{p}{,}\PYG{n}{reliability}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{reliability diagram}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{marker}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{x}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{color}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{k}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}ig = plot\PYGZus{}reliability\PYGZus{}diagram(reliability, confindence, bin\PYGZus{}counts)}
\PYG{c+c1}{\PYGZsh{}plt.close()}
\PYG{c+c1}{\PYGZsh{}print(fig)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{proba\PYGZus{}class1}\PYG{p}{,} \PYG{n}{cox\PYGZus{}p\PYGZus{}correct}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cox}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{lowess\PYGZus{}fit\PYGZus{}p}\PYG{p}{,} \PYG{n}{lowess\PYGZus{}fit\PYGZus{}p\PYGZus{}correct}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Loess with span= 0.5}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{lowess\PYGZus{}fit\PYGZus{}p2}\PYG{p}{,} \PYG{n}{lowess\PYGZus{}fit\PYGZus{}p2\PYGZus{}correct}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Loess with span= 0.3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Predicted Probability}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Corrected Probability}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{grid}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Calibration Curve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[29]:\,\hspace{\fboxrule}\hspace{\fboxsep}}Text(0.5, 1.0, 'Calibration Curve')
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=567\sphinxpxdimen,height=453\sphinxpxdimen]{{notebooks_ici_8_1}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Reference}
\label{\detokenize{notebooks/ici:Reference}}
\sphinxAtStartPar
Cleveland, W.S. (1979) “Robust Locally Weighted Regression and Smoothing Scatterplots”. Journal of the American Statistical Association 74 (368): 829\sphinxhyphen{}836.

\sphinxAtStartPar
Austin, P. C., \& Steyerberg, E. W. (2019). The Integrated Calibration Index (ICI) and related metrics for quantifying the calibration of logistic regression models. Statistics in Medicine, 38(21), 4051\textendash{}4065. \sphinxurl{https://doi.org/10.1002/sim.8281}

\sphinxAtStartPar
Huang, Y., Li, W., Macheret, F., Gabriel, R. A., \& Ohno\sphinxhyphen{}Machado, L. (2020). A tutorial on calibration measurements and calibration models for clinical prediction models. Journal of the American Medical Informatics Association, 27(4), 621\textendash{}633. \sphinxurl{https://doi.org/10.1093/jamia/ocz228}

\sphinxstepscope


\chapter{Spiegelhalter’s Z\sphinxhyphen{}test}
\label{\detokenize{notebooks/spiegelhalter_z:Spiegelhalter's-Z-test}}\label{\detokenize{notebooks/spiegelhalter_z::doc}}

\section{Theoretical background}
\label{\detokenize{notebooks/spiegelhalter_z:Theoretical-background}}
\sphinxAtStartPar
Spiegelhalter’s Z\sphinxhyphen{}test is a statistical test that tests whether a probabilistic model is calibrated. It is named after the statistician David Spiegelhalter, who proposed it in 1986. It is a non\sphinxhyphen{}parametric test that does not require any binning.

\sphinxAtStartPar
The Spiegelhalter’s Z\sphinxhyphen{}test was inspired by the fact that the Brier score (mean squared error) can be decomposed into reliability and resolution. In fact, any proper scoring rule can be decomposed into reliability and resolution, as shown by Brocker (2008). For example, the cross\sphinxhyphen{}entropy can be decomposed into KL\sphinxhyphen{}divergence (reliability) and entropy (resolution).

\sphinxAtStartPar
The Brier score can be decomposed into reliability and resolution as follows:
\begin{equation*}
\begin{split}B = \frac{1}{N} \sum_{i=1}^N (x_i - p_i)^2 = \frac{1}{N} \sum_{i=1}^N (x_i - p_i)(1-2p_i) + \frac{1}{N} \sum_{i=1}^N p_i(1-p_i)\end{split}
\end{equation*}
\sphinxAtStartPar
Where the first term measure the reliability/calibration and the second term measure the resolution/discrimination.

\sphinxAtStartPar
The Variance of the Brier score is:
\begin{equation*}
\begin{split}\text{Var}(B) = \frac{1}{N^2} \sum_{i=1}^N (1-2p_i)^2 p_i (1-p_i)\end{split}
\end{equation*}
\sphinxAtStartPar
and the Speigelhalter’s Z\sphinxhyphen{}test is defined as:
\begin{equation*}
\begin{split}Z = \frac{B - E(B)}{\sqrt{\text{Var}(B)}} = \frac{ \sum_{i=1}^N (x_i - p_i)(1-2p_i)}{\sum_{i=1}^N (1-2p_i)^2 p_i (1-p_i)}\end{split}
\end{equation*}
\sphinxAtStartPar
and \(Z\) is approximately standard normal distributed under the null hypothesis of calibration. Spiegelhalter’s Z\sphinxhyphen{}test has the right size in many situations and it is powerful in many situations. We recommend using Spiegelhalter’s Z\sphinxhyphen{}test to test the calibration of probabilistic models.


\section{Pros of Spiegelhalter’s Z test}
\label{\detokenize{notebooks/spiegelhalter_z:Pros-of-Spiegelhalter's-Z-test}}
\sphinxAtStartPar
Spiegelhalter’s Z test is a statistical test which can provide statistical evidence that the null hypothesis (well\sphinxhyphen{}calibrated) is true or false. It is a non\sphinxhyphen{}parametric test and doesn’t require any hyperparameter tuning. It also doesn’t require any binning of data, which is extremely useful compared to the Hosmer\sphinxhyphen{}Lemeshow test.


\section{Cons of Spiegelhalter’s Z test}
\label{\detokenize{notebooks/spiegelhalter_z:Cons-of-Spiegelhalter's-Z-test}}
\sphinxAtStartPar
The power of Spiegelhalter’s Z test is limited for some cases of miscalibration, such as prevalence shift. However, it is a very powerful test for many other cases of miscalibration.


\section{Calculating the Spieegelhalter Z score and p\sphinxhyphen{}value using calzone}
\label{\detokenize{notebooks/spiegelhalter_z:Calculating-the-Spieegelhalter-Z-score-and-p-value-using-calzone}}
\sphinxAtStartPar
We can call functions from the calzone package to calculate the Spiegelhalter Z score and p\sphinxhyphen{}value directly.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[1]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{reliability\PYGZus{}diagram}\PYG{p}{,}\PYG{n}{data\PYGZus{}loader}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{spiegelhalter\PYGZus{}z\PYGZus{}test}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}

\PYG{n}{wellcal\PYGZus{}dataloader} \PYG{o}{=} \PYG{n}{data\PYGZus{}loader}\PYG{p}{(}\PYG{n}{data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{../../../example\PYGZus{}data/simulated\PYGZus{}welldata.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{z}\PYG{p}{,}\PYG{n}{p\PYGZus{}value} \PYG{o}{=} \PYG{n}{spiegelhalter\PYGZus{}z\PYGZus{}test}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Z\PYGZhy{}score: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{z}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{, p\PYGZhy{}value: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{p\PYGZus{}value}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Z-score: 0.3763269161877356, p-value: 0.7066738713391099
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
We can also use the CalibrationMetrics class

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[2]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{CalibrationMetrics}
\PYG{n}{calmetrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{calmetrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{,} \PYG{n}{wellcal\PYGZus{}dataloader}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SpiegelhalterZ}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[2]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\{'SpiegelhalterZ score': 0.3763269161877356,
 'SpiegelhalterZ p-value': 0.7066738713391099\}
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Testing the size of Spiegelhalter’s z test}
\label{\detokenize{notebooks/spiegelhalter_z:Testing-the-size-of-Spiegelhalter's-z-test}}
\sphinxAtStartPar
Like to HL test, we can check whether the Spiegelhalter’s z test has the correct size.

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[7]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} The size of HL Test}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{123}\PYG{p}{)}
\PYG{n}{fakedata\PYGZus{}generator} \PYG{o}{=} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}\PYG{p}{(}\PYG{n}{alpha\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{beta\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}
\PYG{n}{cal\PYGZus{}metrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{sample\PYGZus{}size} \PYG{o}{=} \PYG{l+m+mi}{1000}
\PYG{n}{simulation\PYGZus{}size} \PYG{o}{=} \PYG{l+m+mi}{10000}
\PYG{n}{results} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{} generate data}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{simulation\PYGZus{}size}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{X}\PYG{p}{,} \PYG{n}{y} \PYG{o}{=} \PYG{n}{fakedata\PYGZus{}generator}\PYG{o}{.}\PYG{n}{generate\PYGZus{}data}\PYG{p}{(}\PYG{n}{sample\PYGZus{}size}\PYG{p}{)}
    \PYG{k}{if} \PYG{n}{i} \PYG{o}{==} \PYG{l+m+mi}{0}\PYG{p}{:}
        \PYG{n}{tempresult} \PYG{o}{=} \PYG{n}{cal\PYGZus{}metrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SpiegelhalterZ}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{return\PYGZus{}numpy}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
        \PYG{n}{keys} \PYG{o}{=} \PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{tempresult}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
        \PYG{n}{results}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{tempresult}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{n}{tempresult} \PYG{o}{=} \PYG{n}{cal\PYGZus{}metrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SpiegelhalterZ}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{return\PYGZus{}numpy}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
        \PYG{n}{results}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{tempresult}\PYG{p}{)}
\PYG{n}{results} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{results}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[8]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Showing the size of the model}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{n}{z\PYGZus{}scores} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n}{p\PYGZus{}values} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{n}{size} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{p\PYGZus{}values} \PYG{o}{\PYGZlt{}} \PYG{l+m+mf}{0.05}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The size of Spiegelhalter}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s z test is :}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{round}\PYG{p}{(}\PYG{n}{size}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
The size of Spiegelhalter's z test is : 0.049
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[9]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{value}\PYG{p}{,}\PYG{n}{\PYGZus{}}\PYG{p}{,}\PYG{n}{\PYGZus{}}\PYG{o}{=}\PYG{n}{plt}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{p\PYGZus{}values}\PYG{p}{,} \PYG{n}{bins}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{density}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{p\PYGZhy{}value}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{histtype}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{step}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{vlines}\PYG{p}{(}\PYG{n}{size}\PYG{p}{,}\PYG{n}{ymin}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{ymax}\PYG{o}{=}\PYG{n}{np}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{n}{value}\PYG{p}{)}\PYG{p}{,}\PYG{n}{linestyle}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+sa}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Size(\PYGZdl{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{alpha=0.05\PYGZdl{}) = }\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{+}\PYG{n+nb}{str}\PYG{p}{(}\PYG{n+nb}{round}\PYG{p}{(}\PYG{n}{size}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}\PYG{n}{colors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{n}{loc}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{upper right}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{p\PYGZhy{}value}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Density}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{P\PYGZhy{}value distribution of the Spiegelhalter}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s z test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[9]:\,\hspace{\fboxrule}\hspace{\fboxsep}}Text(0.5, 1.0, "P-value distribution of the Spiegelhalter's z test")
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=567\sphinxpxdimen,height=453\sphinxpxdimen]{{notebooks_spiegelhalter_z_9_1}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
We can see that Spiegelhalter’s Z test has a accurate size.


\section{Reference}
\label{\detokenize{notebooks/spiegelhalter_z:Reference}}
\sphinxAtStartPar
Spiegelhalter, D. J. (1986). Probabilistic prediction in patient management and clinical trials.

\sphinxAtStartPar
Bröcker, J. (2009). Reliability, Sufficiency, and the Decomposition of Proper Scores. Quarterly Journal of the Royal Meteorological Society, 135(643), 1512\textendash{}1519. \sphinxurl{https://doi.org/10.1002/qj.456}

\sphinxstepscope


\chapter{Prevalence adjustment}
\label{\detokenize{notebooks/prevalence_adjustment:Prevalence-adjustment}}\label{\detokenize{notebooks/prevalence_adjustment::doc}}
\sphinxAtStartPar
In this notebook, we will discuss how prevalence will affect the calibration of the model in a binary classification problem and how to adjust for prevalence differences.

\sphinxAtStartPar
When we discuss calibration, we usually refer to whether the probability output by the model matches the posterior probability of the true outcome.
\begin{equation*}
\begin{split}P(D=1|\hat{p} = p) = p ,\forall p \in [0,1]\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\hat{p}\) is the predicted probability of the true outcome being 1.

\sphinxAtStartPar
However, the posterior probability of the true outcome being 1 depends on the prevalence of the outcome 1. Using Bayes’ theorem, we can derive the following relationship:
\begin{equation*}
\begin{split}P(D=1|\hat{p} = p) = \frac{P(\hat{p} = p|D=1)P(D=1)}{P(\hat{p} = p)}\end{split}
\end{equation*}
\sphinxAtStartPar
The term \(P(\hat{p} = p|D=1)\) is independent of prevalence for a given model. The term \(P(D=1)\) is the prevalence of the outcome 1. The term \(P(\hat{p} = p)\) is the marginal probability of the predicted probability being \(p\) and implicitly depends on the prevalence of the true outcome. We can expand the denominator using the fact that \(P(\hat{p} = p) = P(\hat{p} = p|D=1)\eta + P(\hat{p} = p|D=0)(1-\eta)\). Further rearranging the above equation will lead to the
following equation:
\begin{equation*}
\begin{split}P(D=1|\hat{p}=p) = \frac{\text{LR}(p) \times \eta}{\text{LR}(p) \times \eta + 1 - \eta}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\text{LR}(p) = \frac{P(\hat{p} = p|D=1)}{P(\hat{p} = p|D=0)}\) is the likelihood ratio of the predicted probability being \(p\) given the true outcome being 1 and 0 respectively, and \(\eta\) is the prevalence of the outcome 1.

\sphinxAtStartPar
The likelihood ratio is independent of the prevalence, so that the model can be calibrated for a specific prevalence but will become mis\sphinxhyphen{}calibrated for a different prevalence. We can say such a model is “intrinsically calibrated”, meaning that the likelihood ratio of the model with a specific prevalence produced a correct posterior probability of the true outcome being 1.

\sphinxAtStartPar
An intrinsically calibrated model can be adapted to a population with a different prevalence but the same probability distribution within class. To adjust for prevalence differences, we rely on the fact that the likelihood ratio is independent of the prevalence. We can use the following equation to adjust the predicted probability of the true outcome being 1 for a different prevalence:
\begin{equation*}
\begin{split}P(D=1|\hat{p}=p) = \frac{\eta LR(p)}{\eta LR(p) + (1-\eta)} = p\end{split}
\end{equation*}\begin{equation*}
\begin{split}LR(p) = \frac{p}{1-p} \cdot \frac{1-\eta}{\eta}\end{split}
\end{equation*}\begin{equation*}
\begin{split}P'(D=1|\hat{p}=p) = \frac{\eta' LR(p)}{\eta' LR(p) + (1-\eta')} = \frac{\eta'/(1-\eta')}{(1/p-1)(\eta/(1-\eta))} = p'\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\eta\) is the prevalence of the derivation population (aka the population for which the model is calibrated) and \(\eta'\) is the prevalence of the outcome 1 in the new population. We will refer to \(p'\) as the adjusted probability.

\sphinxAtStartPar
In practice, we might have a dataset with the true label (which we can use to calculate the prevalence \(\eta\)) and predicted probability of the true outcome being 1. We can search for the derivation prevalence \(\eta\) that minimizes cross\sphinxhyphen{}entropy loss between the adjusted probability \(p'\) and the posterior probability of the true outcome being 1.
\begin{equation*}
\begin{split}\min_{\eta} \sum_{i=1}^{N} \left(y_i \log(p_i') + (1-y_i) \log(1-p_i')\right)\end{split}
\end{equation*}
\sphinxAtStartPar
Notice that minimizing cross\sphinxhyphen{}entropy loss with respect to \(\eta\) is equivalent to minimizing the KL divergence since the prevalence adjustment is a monotonic transformation and doesn’t affect the resolution component of the cross\sphinxhyphen{}entropy loss.


\section{Preform prevalence adjustment in calzone}
\label{\detokenize{notebooks/prevalence_adjustment:Preform-prevalence-adjustment-in-calzone}}
\sphinxAtStartPar
We will demonstrate how to perform prevalence adjustment in calzone. The first method is to find optimal prevalence first and apply the adjustment.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[1]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}

\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{find\PYGZus{}optimal\PYGZus{}prevalence}\PYG{p}{,}\PYG{n}{apply\PYGZus{}prevalence\PYGZus{}adjustment}\PYG{p}{,}\PYG{n}{data\PYGZus{}loader}\PYG{p}{,}\PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{c+c1}{\PYGZsh{} We generate data and drop the prevalence}

\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{123}\PYG{p}{)}
\PYG{n}{fakedata\PYGZus{}generator} \PYG{o}{=} \PYG{n}{fake\PYGZus{}binary\PYGZus{}data\PYGZus{}generator}\PYG{p}{(}\PYG{n}{alpha\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{beta\PYGZus{}val}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}
\PYG{n}{X}\PYG{p}{,} \PYG{n}{y} \PYG{o}{=} \PYG{n}{fakedata\PYGZus{}generator}\PYG{o}{.}\PYG{n}{generate\PYGZus{}data}\PYG{p}{(}\PYG{l+m+mi}{5000}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} drop half the outcome 1 prevalence}
\PYG{n}{class\PYGZus{}1\PYGZus{}index} \PYG{o}{=} \PYG{p}{(}\PYG{n}{y}\PYG{o}{==}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{class\PYGZus{}1\PYGZus{}samples} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n}{class\PYGZus{}1\PYGZus{}index}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n}{drop\PYGZus{}indices} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{choice}\PYG{p}{(}\PYG{n}{class\PYGZus{}1\PYGZus{}samples}\PYG{p}{,} \PYG{n}{size}\PYG{o}{=}\PYG{n+nb}{int}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{class\PYGZus{}1\PYGZus{}samples}\PYG{p}{)}\PYG{o}{/}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{,} \PYG{n}{replace}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

\PYG{n}{mask} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{y}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dtype}\PYG{o}{=}\PYG{n+nb}{bool}\PYG{p}{)}
\PYG{n}{mask}\PYG{p}{[}\PYG{n}{drop\PYGZus{}indices}\PYG{p}{]} \PYG{o}{=} \PYG{k+kc}{False}

\PYG{n}{y} \PYG{o}{=} \PYG{n}{y}\PYG{p}{[}\PYG{n}{mask}\PYG{p}{]}
\PYG{n}{X} \PYG{o}{=} \PYG{n}{X}\PYG{p}{[}\PYG{n}{mask}\PYG{p}{]}
\PYG{n}{optimal\PYGZus{}prevalence}\PYG{p}{,}\PYG{n}{adjusted\PYGZus{}p} \PYG{o}{=} \PYG{n}{find\PYGZus{}optimal\PYGZus{}prevalence}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Dataset prevalence: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{y}\PYG{p}{)}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Derived prevalence: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{optimal\PYGZus{}prevalence}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dataset prevalence:  0.3300531914893617
Derived prevalence:  0.49863799264980607
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
The function return both the derived prevalence and the adjusted probability. We can also use the derived prevalence adjustment factor to perform the adjustment mannually.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[3]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Prevalence Adjustment}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{lowess\PYGZus{}regression\PYGZus{}analysis}
\PYG{n}{proba\PYGZus{}adjust} \PYG{o}{=} \PYG{n}{apply\PYGZus{}prevalence\PYGZus{}adjustment}\PYG{p}{(}\PYG{n}{optimal\PYGZus{}prevalence}\PYG{p}{,} \PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Loess ICI before prevalence adjustment: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{lowess\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Loess ICI after prevalence adjustment: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{lowess\PYGZus{}regression\PYGZus{}analysis}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{proba\PYGZus{}adjust}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Loess ICI before prevalence adjustment:  0.07961758926734244
Loess ICI after prevalence adjustment:  0.008745511902314453
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
calzone also provides a argument to perform prevalence adjustment directly from the CalibrationMetrics class.

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[7]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} We calculate the Calibration metrics before and after prevalence adjustment}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{CalibrationMetrics}
\PYG{n}{calmetrics} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{before\PYGZus{}prevalence} \PYG{o}{=} \PYG{n}{calmetrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,}\PYG{n}{X}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ECE\PYGZhy{}H}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{COX}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Loess}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{perform\PYGZus{}pervalance\PYGZus{}adjustment}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{after\PYGZus{}prevalence} \PYG{o}{=} \PYG{n}{calmetrics}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,}\PYG{n}{X}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ECE\PYGZhy{}H}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{COX}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Loess}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{perform\PYGZus{}pervalance\PYGZus{}adjustment}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[8]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k}{for} \PYG{n}{key} \PYG{o+ow}{in} \PYG{n}{before\PYGZus{}prevalence}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{key}\PYG{p}{)}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{before adjustment:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{before\PYGZus{}prevalence}\PYG{p}{[}\PYG{n}{key}\PYG{p}{]}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{, after adjustment:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{after\PYGZus{}prevalence}\PYG{p}{[}\PYG{n}{key}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
ECE-H topclass
before adjustment: 0.014081013182402267 , after adjustment: 0.010355911839501922
ECE-H
before adjustment: 0.0841517729106883 , after adjustment: 0.013671230516636386
COX coef
before adjustment: 0.9400481147756811 , after adjustment: 0.9400481147756811
COX intercept
before adjustment: -0.6897839569176842 , after adjustment: -0.029403495083063648
COX coef lowerci
before adjustment: 0.8754203499121679 , after adjustment: 0.8754203499121678
COX coef upperci
before adjustment: 1.0046758796391944 , after adjustment: 1.0046758796391944
COX intercept lowerci
before adjustment: -0.7837388214288888 , after adjustment: -0.12775157222121533
COX intercept upperci
before adjustment: -0.5958290924064796 , after adjustment: 0.06894458205508802
COX ICI
before adjustment: 0.0841517733462589 , after adjustment: 0.007508966220374058
Loess ICI
before adjustment: 0.07961758926734244 , after adjustment: 0.008745511902314453
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Prevalence adjustment and constant shift in logit of class\sphinxhyphen{}of\sphinxhyphen{}interest}
\label{\detokenize{notebooks/prevalence_adjustment:Prevalence-adjustment-and-constant-shift-in-logit-of-class-of-interest}}
\sphinxAtStartPar
In the section, we will prove that the prevalence shift is equivalent to a constant shift in logit of class\sphinxhyphen{}of\sphinxhyphen{}interest. In other words, prevalence adjustment can be done by addint a constant to the logit of class\sphinxhyphen{}of\sphinxhyphen{}interest. For the calibrated case, the likelihood ratio of the two classes is:
\begin{equation*}
\begin{split}LR(p) = \frac{\frac{e^{x_2}}{e^{x_1} + e^{x_2}}}{\frac{e^{x_1}}{e^{x_1} + e^{x_2}}} \cdot \frac{1-\eta}{\eta} = e^{x_2 - x_1} \cdot \frac{1-\eta}{\eta}\end{split}
\end{equation*}
\sphinxAtStartPar
Assumer we add a constant \(c\) to the logit of class\sphinxhyphen{}of\sphinxhyphen{}interest (\(x_2\) here), the likelihood ratio becomes:
\begin{equation*}
\begin{split}LR'(p) = e^{x_2 - x_1 + c} \cdot \frac{1-\eta}{\eta}\end{split}
\end{equation*}
\sphinxAtStartPar
And the posterior probability becomes:
\begin{equation*}
\begin{split}P'(D=1|\hat{p}=p) = \frac{\eta LR'(p)}{\eta LR'(p) + (1-\eta)} = \frac{\eta LR(p) \cdot e^c}{\eta LR(p) \cdot e^c + (1-\eta)}\end{split}
\end{equation*}
\sphinxAtStartPar
Which is equivalent to the posterior probability after prevalence adjustment:
\begin{equation*}
\begin{split}\frac{\eta' LR(p)}{\eta' LR(p) + (1-\eta')}\end{split}
\end{equation*}
\sphinxAtStartPar
By setting
\begin{equation*}
\begin{split}\eta' = \frac{1}{1 + e^a \left(\frac{1-\eta}{\eta}\right)}\end{split}
\end{equation*}
\sphinxAtStartPar
Therefore, prevalence adjustment is equivalent to a constant shift in logit of class\sphinxhyphen{}of\sphinxhyphen{}interest.


\section{References}
\label{\detokenize{notebooks/prevalence_adjustment:References}}
\sphinxAtStartPar
Chen, W., Sahiner, B., Samuelson, F., Pezeshk, A., \& Petrick, N. (2018). Calibration of medical diagnostic classifier scores to the probability of disease. Statistical Methods in Medical Research, 27(5), 1394\textendash{}1409. \sphinxurl{https://doi.org/10.1177/0962280216661371}

\sphinxAtStartPar
Gu, W., \& Pepe, M. S. (2011). Estimating the diagnostic likelihood ratio of a continuous marker. Biostatistics, 12(1), 87\textendash{}101. \sphinxurl{https://doi.org/10.1093/biostatistics/kxq045}

\sphinxAtStartPar
Tian, J., Liu, Y.\sphinxhyphen{}C., Glaser, N., Hsu, Y.\sphinxhyphen{}C., \& Kira, Z. (2020). Posterior Re\sphinxhyphen{}calibration for Imbalanced Datasets (No. arXiv:2010.11820). arXiv. http://arxiv.org/abs/2010.11820

\sphinxstepscope


\chapter{Subgroup analysis}
\label{\detokenize{notebooks/subgroup:Subgroup-analysis}}\label{\detokenize{notebooks/subgroup::doc}}
\sphinxAtStartPar
In many real\sphinxhyphen{}world applications, we are not just interested in the calibration of the overall population, but also interested in the calibration for subgroups within the population. calzone provides a simple way to perform subgroup analysis given some data input format. In order to perform subgroup analysis, the input csv file should contain the following columns:

\sphinxAtStartPar
proba\_0, proba\_1, …, proba\_n, subgroup\_1, subgroup\_2, …, subgroup\_m, label

\sphinxAtStartPar
where n \textgreater{}= 1 and m \textgreater{}= 1.

\sphinxAtStartPar
In this example, we will use the example simulated dataset in the calzone package with only one subgroup field and two subgroups. See quickstart for more details.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[1]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} import the packages and read the data}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{data\PYGZus{}loader}
\PYG{k+kn}{from} \PYG{n+nn}{calzone}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{CalibrationMetrics}

\PYG{n}{dataset} \PYG{o}{=} \PYG{n}{data\PYGZus{}loader}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}data\PYGZus{}subgroup.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Whether the dataset has subgroup:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{have\PYGZus{}subgroup}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Create the CalibrationMetrics class}
\PYG{n}{metrics\PYGZus{}cal} \PYG{o}{=} \PYG{n}{CalibrationMetrics}\PYG{p}{(}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Whether the dataset has subgroup: True
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[10]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} subgroup analysis for each group}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} You can preform other analysis during the loop (eg. plotting the reliability diagram etc)}
\PYG{k}{for} \PYG{n}{i}\PYG{p}{,}\PYG{n}{subgroup\PYGZus{}column} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{subgroup\PYGZus{}indices}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{subgroup }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{i}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{k}{for} \PYG{n}{j}\PYG{p}{,}\PYG{n}{subgroup\PYGZus{}class} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{subgroups\PYGZus{}class}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{subgroup }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{i}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ class }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{subgroup\PYGZus{}class}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{n}{proba} \PYG{o}{=} \PYG{n}{dataset}\PYG{o}{.}\PYG{n}{probs}\PYG{p}{[}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{subgroups\PYGZus{}index}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{[}\PYG{n}{j}\PYG{p}{]}\PYG{p}{,}\PYG{p}{:}\PYG{p}{]}
        \PYG{n}{label} \PYG{o}{=} \PYG{n}{dataset}\PYG{o}{.}\PYG{n}{labels}\PYG{p}{[}\PYG{n}{dataset}\PYG{o}{.}\PYG{n}{subgroups\PYGZus{}index}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{[}\PYG{n}{j}\PYG{p}{]}\PYG{p}{]}
        \PYG{n}{result} \PYG{o}{=} \PYG{n}{metrics\PYGZus{}cal}\PYG{o}{.}\PYG{n}{calculate\PYGZus{}metrics}\PYG{p}{(}\PYG{n}{label}\PYG{p}{,} \PYG{n}{proba}\PYG{p}{,}\PYG{n}{metrics}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{all}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
        \PYG{k}{for} \PYG{n}{metric} \PYG{o+ow}{in} \PYG{n}{result}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{metric}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{result}\PYG{p}{[}\PYG{n}{metric}\PYG{p}{]}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
subgroup 1
subgroup 1 class A
SpiegelhalterZ score: 0.3763269161877356
SpiegelhalterZ p-value: 0.7066738713391099
ECE-H topclass: 0.009608653731328977
ECE-H: 0.01208775955804901
MCE-H topclass: 0.03926468843081976
MCE-H: 0.04848338618970194
HL-H score: 8.884991559088098
HL-H p-value: 0.35209071874348785
ECE-C topclass: 0.009458033653818828
ECE-C: 0.008733966945443138
MCE-C topclass: 0.020515047600205505
MCE-C: 0.02324031223486256
HL-C score: 3.694947603203135
HL-C p-value: 0.8835446575708198
COX coef: 0.9942499557748269
COX intercept: -0.04497652296600376
COX coef lowerci: 0.9372902801721911
COX coef upperci: 1.0512096313774626
COX intercept lowerci: -0.12348577118577644
COX intercept upperci: 0.03353272525376893
COX ICI: 0.005610391483826338
Loess ICI: 0.00558856942568957
subgroup 1 class B
SpiegelhalterZ score: 27.93575342117766
SpiegelhalterZ p-value: 0.0
ECE-H topclass: 0.07658928982434714
ECE-H: 0.0765892898243467
MCE-H topclass: 0.1327565894838103
MCE-H: 0.16250572519432438
HL-H score: 910.4385762101924
HL-H p-value: 0.0
ECE-C topclass: 0.07429481165606829
ECE-C: 0.07479369479609524
MCE-C topclass: 0.14090872416947742
MCE-C: 0.14045600565696226
HL-C score: 2246.1714434139853
HL-C p-value: 0.0
COX coef: 0.5071793536874274
COX intercept: 0.00037947714112375366
COX coef lowerci: 0.47838663128188996
COX coef upperci: 0.5359720760929648
COX intercept lowerci: -0.07796623141885761
COX intercept upperci: 0.07872518570110512
COX ICI: 0.07746407648179383
Loess ICI: 0.06991428582761099
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[11]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} An alernative way to do the same thing is through command line interface}

\PYG{o}{\PYGZpc{}}\PYG{k}{run} ../../../cal\PYGZus{}metrics.py \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{csv\PYGZus{}file} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../../../example\PYGZus{}data/simulated\PYGZus{}data\PYGZus{}subgroup.csv}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{metrics} \PYG{n+nb}{all} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{class\PYGZus{}to\PYGZus{}calculate} \PYG{l+m+mi}{1} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{num\PYGZus{}bins} \PYG{l+m+mi}{10} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{verbose}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Metrics:
SpiegelhalterZ score: 18.326500460344757
SpiegelhalterZ p-value: 0.0
ECE-H topclass: 0.04154425366233608
ECE-H: 0.041606274177861564
MCE-H topclass: 0.05506859806121056
MCE-H: 0.06291857721845223
HL-H score: 429.7315889789045
HL-H p-value: 0.0
ECE-C topclass: 0.04153827551437989
ECE-C: 0.03813373547517625
MCE-C topclass: 0.06521747269553313
MCE-C: 0.06426881466822676
HL-C score: 1138.8421218049589
HL-C p-value: 0.0
COX coef: 0.6682652785932737
COX intercept: -0.019974208464277905
COX coef lowerci: 0.6406305507074329
COX coef upperci: 0.6959000064791144
COX intercept lowerci: -0.07427409213097665
COX intercept upperci: 0.03432567520242083
COX ICI: 0.04920919519153327
Loess ICI: 0.03714791811671051
Metrics for subgroup subgroup\_1\_group\_A:
SpiegelhalterZ score: 0.3763269161877356
SpiegelhalterZ p-value: 0.7066738713391099
ECE-H topclass: 0.009608653731328977
ECE-H: 0.01208775955804901
MCE-H topclass: 0.03926468843081976
MCE-H: 0.04848338618970194
HL-H score: 8.884991559088098
HL-H p-value: 0.35209071874348785
ECE-C topclass: 0.009458033653818828
ECE-C: 0.008733966945443138
MCE-C topclass: 0.020515047600205505
MCE-C: 0.02324031223486256
HL-C score: 3.694947603203135
HL-C p-value: 0.8835446575708198
COX coef: 0.9942499557748269
COX intercept: -0.04497652296600376
COX coef lowerci: 0.9372902801721911
COX coef upperci: 1.0512096313774626
COX intercept lowerci: -0.12348577118577644
COX intercept upperci: 0.03353272525376893
COX ICI: 0.005610391483826338
Loess ICI: 0.00558856942568957
Metrics for subgroup subgroup\_1\_group\_B:
SpiegelhalterZ score: 27.93575342117766
SpiegelhalterZ p-value: 0.0
ECE-H topclass: 0.07658928982434714
ECE-H: 0.0765892898243467
MCE-H topclass: 0.1327565894838103
MCE-H: 0.16250572519432438
HL-H score: 910.4385762101924
HL-H p-value: 0.0
ECE-C topclass: 0.07429481165606829
ECE-C: 0.07479369479609524
MCE-C topclass: 0.14090872416947742
MCE-C: 0.14045600565696226
HL-C score: 2246.1714434139853
HL-C p-value: 0.0
COX coef: 0.5071793536874274
COX intercept: 0.00037947714112375366
COX coef lowerci: 0.47838663128188996
COX coef upperci: 0.5359720760929648
COX intercept lowerci: -0.07796623141885761
COX intercept upperci: 0.07872518570110512
COX ICI: 0.07746407648179383
Loess ICI: 0.06991428582761099
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[ ]:\,\hspace{\fboxrule}\hspace{\fboxsep}}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxstepscope


\chapter{calzone}
\label{\detokenize{modules:calzone}}\label{\detokenize{modules::doc}}
\sphinxstepscope


\section{calzone package}
\label{\detokenize{calzone:calzone-package}}\label{\detokenize{calzone::doc}}

\subsection{Submodules}
\label{\detokenize{calzone:submodules}}

\subsection{calzone.metrics module}
\label{\detokenize{calzone:module-calzone.metrics}}\label{\detokenize{calzone:calzone-metrics-module}}\index{module@\spxentry{module}!calzone.metrics@\spxentry{calzone.metrics}}\index{calzone.metrics@\spxentry{calzone.metrics}!module@\spxentry{module}}
\sphinxAtStartPar
Metrics calculation functions for the Calibration Measure package.
\index{CalibrationMetrics (class in calzone.metrics)@\spxentry{CalibrationMetrics}\spxextra{class in calzone.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.CalibrationMetrics}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{calzone.metrics.}}\sphinxbfcode{\sphinxupquote{CalibrationMetrics}}}{\sphinxparam{\DUrole{n}{class\_to\_calculate}\DUrole{o}{=}\DUrole{default_value}{1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_bins}\DUrole{o}{=}\DUrole{default_value}{10}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\sphinxAtStartPar
A class for calculating calibration metrics for classification models.
\index{\_\_init\_\_() (calzone.metrics.CalibrationMetrics method)@\spxentry{\_\_init\_\_()}\spxextra{calzone.metrics.CalibrationMetrics method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.CalibrationMetrics.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{class\_to\_calculate}\DUrole{o}{=}\DUrole{default_value}{1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_bins}\DUrole{o}{=}\DUrole{default_value}{10}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Initialize the CalibrationMetrics class.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_calculate}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The class index to calculate the metrics for. Defaults to 1.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_bins}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Number of bins to use for the ECE/MCE/HL calculations. Defaults to 10.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{bootstrap() (calzone.metrics.CalibrationMetrics method)@\spxentry{bootstrap()}\spxextra{calzone.metrics.CalibrationMetrics method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.CalibrationMetrics.bootstrap}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{bootstrap}}}{\sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{metrics}}\sphinxparamcomma \sphinxparam{\DUrole{n}{perform\_pervalance\_adjustment}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{n}{n\_samples}\DUrole{o}{=}\DUrole{default_value}{1000}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Run bootstrap and return a numpy structured array with correct field names.

\sphinxAtStartPar
This function performs bootstrap resampling to estimate the distribution of calibration metrics.
It generates multiple samples with replacement from the input data and calculates the specified
metrics for each sample.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True labels.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{metrics}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{ of }}\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} List of metric names to calculate.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{perform\_pervalance\_adjustment}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Whether to perform prevalence adjustment for each bootstrap sample. Defaults to False.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{n\_samples}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Number of bootstrap samples to generate. Defaults to 1000.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{**kwargs}} \textendash{} Additional keyword arguments to pass to the metric calculation functions.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{numpy.ndarray} \textendash{} A structured array containing the bootstrapped metrics. Each field in the array
corresponds to a metric, and each row represents a bootstrap sample.

\end{description}\end{quote}

\end{fulllineitems}

\index{calculate\_metrics() (calzone.metrics.CalibrationMetrics method)@\spxentry{calculate\_metrics()}\spxextra{calzone.metrics.CalibrationMetrics method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.CalibrationMetrics.calculate_metrics}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{calculate\_metrics}}}{\sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{metrics}}\sphinxparamcomma \sphinxparam{\DUrole{n}{perform\_pervalance\_adjustment}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{n}{return\_numpy}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate the specified calibration metrics.

\sphinxAtStartPar
This function computes various calibration metrics for binary classification models.
It supports multiple metrics and can perform prevalence adjustment if needed.

\sphinxAtStartPar
List of available metrics:
\begin{itemize}
\item {} 
\sphinxAtStartPar
SpiegelhalterZ: Spiegelhalter’s Z\sphinxhyphen{}test for calibration

\item {} 
\sphinxAtStartPar
ECE\sphinxhyphen{}H: Expected Calibration Error with equal\sphinxhyphen{}space binning

\item {} 
\sphinxAtStartPar
MCE\sphinxhyphen{}H: Maximum Calibration Error with equal\sphinxhyphen{}space binning

\item {} 
\sphinxAtStartPar
HL\sphinxhyphen{}H: Hosmer\sphinxhyphen{}Lemeshow test with equal\sphinxhyphen{}space binning

\item {} 
\sphinxAtStartPar
ECE\sphinxhyphen{}C: Expected Calibration Error with equal\sphinxhyphen{}count binning

\item {} 
\sphinxAtStartPar
MCE\sphinxhyphen{}C: Maximum Calibration Error with equal\sphinxhyphen{}count binning

\item {} 
\sphinxAtStartPar
HL\sphinxhyphen{}C: Hosmer\sphinxhyphen{}Lemeshow test with equal\sphinxhyphen{}count binning

\item {} 
\sphinxAtStartPar
COX: Cox regression analysis

\item {} 
\sphinxAtStartPar
Loess: Locally Estimated Scatterplot Smoothing regression analysis

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} True labels.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Predicted probabilities.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{metrics}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{ of }}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{\textquotesingle{}all\textquotesingle{}}}) \textendash{} List of metric names to calculate. If ‘all’, calculates all available metrics.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{perform\_pervalance\_adjustment}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Whether to perform prevalence adjustment. Defaults to False.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_numpy}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Whether to return the results as a numpy array. Defaults to False.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{**kwargs}} \textendash{} Additional keyword arguments to pass to the metric calculation functions.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{dict or numpy.ndarray} \textendash{} A dictionary containing the calculated metrics, or a numpy array if return\_numpy is True.

\end{description}\end{quote}

\end{fulllineitems}

\index{optimal\_prevalence\_adjustment() (calzone.metrics.CalibrationMetrics method)@\spxentry{optimal\_prevalence\_adjustment()}\spxextra{calzone.metrics.CalibrationMetrics method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.CalibrationMetrics.optimal_prevalence_adjustment}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{optimal\_prevalence\_adjustment}}}{\sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Perform optimal prevalence adjustment and return adjusted probabilities.

\sphinxAtStartPar
This function finds the optimal prevalence value that minimizes the difference
between the predicted and actual positive rates, and then adjusts the input
probabilities accordingly.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True labels.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{optimal\_prevalence} (\sphinxstyleemphasis{float}) \textendash{} Optimal prevalence value.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{adjusted\_proba} (\sphinxstyleemphasis{array\sphinxhyphen{}like}) \textendash{} Adjusted probabilities. First column is the adjusted probabilities for the other class,
second column is the adjusted probabilities for the class of interest.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{cal\_ICI() (in module calzone.metrics)@\spxentry{cal\_ICI()}\spxextra{in module calzone.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.cal_ICI}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.metrics.}}\sphinxbfcode{\sphinxupquote{cal\_ICI}}}{\sphinxparam{\DUrole{n}{func}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{points}\DUrole{o}{=}\DUrole{default_value}{1000}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_calculate}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate the Integrated Calibration Index (ICI) for a given calibration function.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{func}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}) \textendash{} The calibration function to evaluate.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities for each class. Shape (n\_samples, n\_classes).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{points}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Number of points to use for numerical integration. Defaults to 1000.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_calculate}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The class index to calculate the ICI for. Defaults to 1.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{float} \textendash{} The Integrated Calibration Index (ICI) value.

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
The ICI is calculated by integrating the absolute difference between
the calibration function and the identity function, weighted by the
density of the predicted probabilities.
\end{sphinxadmonition}

\end{fulllineitems}

\index{cal\_ICI\_cox() (in module calzone.metrics)@\spxentry{cal\_ICI\_cox()}\spxextra{in module calzone.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.cal_ICI_cox}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.metrics.}}\sphinxbfcode{\sphinxupquote{cal\_ICI\_cox}}}{\sphinxparam{\DUrole{n}{coef}}\sphinxparamcomma \sphinxparam{\DUrole{n}{intercept}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_calculate}\DUrole{o}{=}\DUrole{default_value}{1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{epsilon}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}10}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate the Integrated Calibration Index (ICI) for a given Cox regression model.

\sphinxAtStartPar
The ICI measures the average absolute difference between the predicted probabilities
and the probabilities transformed by the fitted Cox regression model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{coef}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The coefficient (slope) from the Cox regression.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{intercept}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The intercept from the Cox regression.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities. Should be of shape (n\_samples, n\_classes).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_calculate}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The class to calculate the ICI for in multi\sphinxhyphen{}class problems. Default is 1.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{epsilon}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Small value to avoid numerical instability when clipping probabilities. Default is 1e\sphinxhyphen{}10.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{ICI} (\sphinxstyleemphasis{float}) \textendash{} The Integrated Calibration Index.

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Lower ICI values indicate better calibration.

\item {} 
\sphinxAtStartPar
The function applies the inverse logit transformation to the predicted probabilities
using the coefficients from the Cox regression.

\end{itemize}
\end{sphinxadmonition}

\end{fulllineitems}

\index{calculate\_ece\_mce() (in module calzone.metrics)@\spxentry{calculate\_ece\_mce()}\spxextra{in module calzone.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.calculate_ece_mce}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.metrics.}}\sphinxbfcode{\sphinxupquote{calculate\_ece\_mce}}}{\sphinxparam{\DUrole{n}{reliability}}\sphinxparamcomma \sphinxparam{\DUrole{n}{confindence}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bin\_counts}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate Expected Calibration Error (ECE) and Maximum Calibration Error (MCE).

\sphinxAtStartPar
These metrics assess the calibration of a classification model by comparing
predicted probabilities to observed frequencies.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{reliability}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Array of observed frequencies for each bin.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{confindence}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Array of predicted probabilities for each bin.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bin\_counts}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Array of sample counts in each bin.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{ece} (\sphinxstyleemphasis{float}) \textendash{} The Expected Calibration Error.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{mce} (\sphinxstyleemphasis{float}) \textendash{} The Maximum Calibration Error.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}\begin{itemize}
\item {} 
\sphinxAtStartPar
ECE is a weighted average of the absolute differences between confidence and reliability.

\item {} 
\sphinxAtStartPar
MCE is the maximum absolute difference between confidence and reliability across all bins.

\item {} 
\sphinxAtStartPar
Lower values of both ECE and MCE indicate better calibration.

\end{itemize}
\end{sphinxadmonition}

\end{fulllineitems}

\index{cox\_regression\_analysis() (in module calzone.metrics)@\spxentry{cox\_regression\_analysis()}\spxextra{in module calzone.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.cox_regression_analysis}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.metrics.}}\sphinxbfcode{\sphinxupquote{cox\_regression\_analysis}}}{\sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{epsilon}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}10}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_calculate}\DUrole{o}{=}\DUrole{default_value}{1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{print\_results}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{n}{fix\_intercept}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{n}{fix\_slope}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Perform Cox regression analysis for classification calibration.

\sphinxAtStartPar
This function fits a logistic regression model to the logit of predicted probabilities
to assess the calibration of classification predictions.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True binary labels. If multi\sphinxhyphen{}class, will be converted to binary.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities. Should be of shape (n\_samples, n\_classes).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{epsilon}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Small value to avoid log(0) errors. Default is 1e\sphinxhyphen{}10.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_calculate}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The class to treat as the positive class in binary classification. Default is 1.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{print\_results}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} If True, prints the summary of the logistic regression results. Default is False.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fix\_intercept}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} If True, fixes the intercept to 0. Can’t be used with fix\_slope. Default is False.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fix\_slope}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} If True, fixes the coefficient to 1. Can’t be used with fix\_intercept. Default is False.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{coef} (\sphinxstyleemphasis{float}) \textendash{} The coefficient (slope) of the Cox regression.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{intercept} (\sphinxstyleemphasis{float}) \textendash{} The intercept of the Cox regression.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{coef\_ci} (\sphinxstyleemphasis{tuple}) \textendash{} The confidence interval for the coefficient.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{intercept\_ci} (\sphinxstyleemphasis{tuple}) \textendash{} The confidence interval for the intercept.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}\begin{itemize}
\item {} 
\sphinxAtStartPar
A well\sphinxhyphen{}calibrated model should have a coefficient close to 1 and an intercept close to 0.

\item {} 
\sphinxAtStartPar
The function clips probabilities to avoid numerical instability.

\item {} 
\sphinxAtStartPar
For multi\sphinxhyphen{}class problems, the function converts the problem to binary classification
based on the specified class\_to\_calculate.

\end{itemize}
\end{sphinxadmonition}

\end{fulllineitems}

\index{get\_CI() (in module calzone.metrics)@\spxentry{get\_CI()}\spxextra{in module calzone.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.get_CI}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.metrics.}}\sphinxbfcode{\sphinxupquote{get\_CI}}}{\sphinxparam{\DUrole{n}{result}}\sphinxparamcomma \sphinxparam{\DUrole{n}{alpha}\DUrole{o}{=}\DUrole{default_value}{0.05}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate confidence intervals for each field in the result.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{result}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Structured array containing the results for which to calculate confidence intervals.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{alpha}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The significance level for the confidence interval calculation. Defaults to 0.05.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{dict} \textendash{} A dictionary where keys are field names from the input array and values
are tuples containing the lower and upper bounds of the confidence interval.

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
This function calculates percentile\sphinxhyphen{}based confidence intervals for each field
in the input structured array. It’s useful for bootstrap or Monte Carlo simulations.
\end{sphinxadmonition}

\end{fulllineitems}

\index{hosmer\_lemeshow\_test() (in module calzone.metrics)@\spxentry{hosmer\_lemeshow\_test()}\spxextra{in module calzone.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.hosmer_lemeshow_test}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.metrics.}}\sphinxbfcode{\sphinxupquote{hosmer\_lemeshow\_test}}}{\sphinxparam{\DUrole{n}{reliability}}\sphinxparamcomma \sphinxparam{\DUrole{n}{confidence}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bin\_count}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the Hosmer\sphinxhyphen{}Lemeshow test for goodness of fit.

\sphinxAtStartPar
This test is used to assess the calibration of binary classification models with full probability outputs.
It compares observed and expected frequencies of events in groups of the data.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{reliability}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Observed proportion of positive samples in each bin.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{confidence}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities for each bin.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bin\_count}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Number of samples in each bin.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{chi\_squared} (\sphinxstyleemphasis{float}) \textendash{} The chi\sphinxhyphen{}squared statistic of the Hosmer\sphinxhyphen{}Lemeshow test.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{p\_value} (\sphinxstyleemphasis{float}) \textendash{} The p\sphinxhyphen{}value associated with the chi\sphinxhyphen{}squared statistic.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{df} (\sphinxstyleemphasis{int}) \textendash{} The degrees of freedom for the test.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}\begin{itemize}
\item {} 
\sphinxAtStartPar
The Hosmer\sphinxhyphen{}Lemeshow test is widely used for assessing calibration in probabiliticst models.

\item {} 
\sphinxAtStartPar
A small p\sphinxhyphen{}value (typically \textless{} 0.05) suggests that the model is a poor fit to the data.

\item {} 
\sphinxAtStartPar
This test can be sensitive to the number of groups and sample size.

\item {} 
\sphinxAtStartPar
It is recommended to use the Hosmer\sphinxhyphen{}Lemeshow test in conjunction with other metrics.

\end{itemize}
\end{sphinxadmonition}

\end{fulllineitems}

\index{logit\_func() (in module calzone.metrics)@\spxentry{logit\_func()}\spxextra{in module calzone.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.logit_func}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.metrics.}}\sphinxbfcode{\sphinxupquote{logit\_func}}}{\sphinxparam{\DUrole{n}{coef}}\sphinxparamcomma \sphinxparam{\DUrole{n}{intercept}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Create a logistic function with given coefficient and intercept.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{coef}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The coefficient (slope) of the logistic function.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{intercept}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The intercept of the logistic function.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{callable} \textendash{} A function that takes an input x and returns the logistic function value.

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
The returned function applies the logistic transformation:
f(x) = 1 / (1 + exp(\sphinxhyphen{}(coef * log(x / (1 \sphinxhyphen{} x)) + intercept)))
\end{sphinxadmonition}

\end{fulllineitems}

\index{lowess\_regression\_analysis() (in module calzone.metrics)@\spxentry{lowess\_regression\_analysis()}\spxextra{in module calzone.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.lowess_regression_analysis}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.metrics.}}\sphinxbfcode{\sphinxupquote{lowess\_regression\_analysis}}}{\sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{epsilon}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}10}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_calculate}\DUrole{o}{=}\DUrole{default_value}{1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{span}\DUrole{o}{=}\DUrole{default_value}{0.5}}\sphinxparamcomma \sphinxparam{\DUrole{n}{delta}\DUrole{o}{=}\DUrole{default_value}{0.001}}\sphinxparamcomma \sphinxparam{\DUrole{n}{it}\DUrole{o}{=}\DUrole{default_value}{0}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Perform Lowess regression analysis for classification calibration.

\sphinxAtStartPar
This function applies Locally Weighted Scatterplot Smoothing (LOWESS) to assess
the calibration of classification predictions.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True binary labels. If multi\sphinxhyphen{}class, will be converted to binary.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities. Should be of shape (n\_samples, n\_classes).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{epsilon}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Small value to avoid numerical instability when clipping probabilities. Defaults to 1e\sphinxhyphen{}10.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_calculate}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The class to treat as the positive class in binary classification. Defaults to 1.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{span}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The fraction of the data used when estimating each y\sphinxhyphen{}value. Defaults to 0.5.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delta}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Distance within which to use linear\sphinxhyphen{}interpolation instead of weighted regression. Defaults to 0.001.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{it}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The number of residual\sphinxhyphen{}based reweightings to perform. Defaults to 0.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{ICI} (\sphinxstyleemphasis{float}) \textendash{} The Integrated Calibration Index.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{sorted\_proba} (\sphinxstyleemphasis{array\sphinxhyphen{}like}) \textendash{} Sorted predicted probabilities.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{smoothed\_proba} (\sphinxstyleemphasis{array\sphinxhyphen{}like}) \textendash{} Corresponding LOWESS\sphinxhyphen{}smoothed actual probabilities.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}\begin{itemize}
\item {} 
\sphinxAtStartPar
The function clips probabilities to avoid numerical instability.

\item {} 
\sphinxAtStartPar
For multi\sphinxhyphen{}class problems, the function converts the problem to binary classification
based on the specified class\_to\_calculate.

\item {} 
\sphinxAtStartPar
The Integrated Calibration Index (ICI) provides a measure of calibration error,
with lower values indicating better calibration.

\end{itemize}
\end{sphinxadmonition}

\end{fulllineitems}

\index{spiegelhalter\_z\_test() (in module calzone.metrics)@\spxentry{spiegelhalter\_z\_test()}\spxextra{in module calzone.metrics}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.metrics.spiegelhalter_z_test}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.metrics.}}\sphinxbfcode{\sphinxupquote{spiegelhalter\_z\_test}}}{\sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_calculate}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Perform Spiegelhalter’s Z\sphinxhyphen{}test for calibration of probabilistic predictions.

\sphinxAtStartPar
This test assesses whether predicted probabilities are well\sphinxhyphen{}calibrated by comparing
them to observed outcomes.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True labels of the samples.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities for each class. Shape should be (n\_samples, n\_classes).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_calculate}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Index of the class to calculate the test for. Default is 1.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{z\_score} (\sphinxstyleemphasis{float}) \textendash{} The z\sphinxhyphen{}score of the Spiegelhalter’s Z\sphinxhyphen{}test.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{p\_value} (\sphinxstyleemphasis{float}) \textendash{} The p\sphinxhyphen{}value associated with the z\sphinxhyphen{}score.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}\begin{itemize}
\item {} 
\sphinxAtStartPar
This test is used to assess the calibration of a classification model.

\item {} 
\sphinxAtStartPar
A small p\sphinxhyphen{}value (typically \textless{} 0.05) suggests that the model is poorly calibrated.

\item {} 
\sphinxAtStartPar
The test assumes that predictions are independent and identically distributed.

\end{itemize}
\end{sphinxadmonition}

\end{fulllineitems}



\subsection{calzone.utils module}
\label{\detokenize{calzone:module-calzone.utils}}\label{\detokenize{calzone:calzone-utils-module}}\index{module@\spxentry{module}!calzone.utils@\spxentry{calzone.utils}}\index{calzone.utils@\spxentry{calzone.utils}!module@\spxentry{module}}
\sphinxAtStartPar
Uitlity functions for the Calibration Measure package.
\index{apply\_prevalence\_adjustment() (in module calzone.utils)@\spxentry{apply\_prevalence\_adjustment()}\spxextra{in module calzone.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.apply_prevalence_adjustment}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.utils.}}\sphinxbfcode{\sphinxupquote{apply\_prevalence\_adjustment}}}{\sphinxparam{\DUrole{n}{adjusted\_prevalence}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_calculate}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Apply the prevalence adjustment method.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{adjusted\_prevalence}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The adjusted prevalence to test.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True labels.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_calculate}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The class index to adjust. Default is 1.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{numpy.ndarray} \textendash{} Adjusted probabilities.

\end{description}\end{quote}

\end{fulllineitems}

\index{data\_loader (class in calzone.utils)@\spxentry{data\_loader}\spxextra{class in calzone.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{calzone.utils.}}\sphinxbfcode{\sphinxupquote{data\_loader}}}{\sphinxparam{\DUrole{n}{data\_path}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\sphinxAtStartPar
A class for loading and preprocessing data from a CSV file.

\sphinxAtStartPar
This class handles various data formats, including those with or without subgroup information and headers.
\index{data\_path (calzone.utils.data\_loader attribute)@\spxentry{data\_path}\spxextra{calzone.utils.data\_loader attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.data_path}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{data\_path}}}
\pysigstopsignatures
\sphinxAtStartPar
Path to the CSV file containing the data.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
str

\end{description}\end{quote}

\end{fulllineitems}

\index{Header (calzone.utils.data\_loader attribute)@\spxentry{Header}\spxextra{calzone.utils.data\_loader attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.Header}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{Header}}}
\pysigstopsignatures
\sphinxAtStartPar
Array of column headers from the CSV file.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{subgroups (calzone.utils.data\_loader attribute)@\spxentry{subgroups}\spxextra{calzone.utils.data\_loader attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.subgroups}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{subgroups}}}
\pysigstopsignatures
\sphinxAtStartPar
List of subgroup column names, if present.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
list

\end{description}\end{quote}

\end{fulllineitems}

\index{subgroup\_indices (calzone.utils.data\_loader attribute)@\spxentry{subgroup\_indices}\spxextra{calzone.utils.data\_loader attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.subgroup_indices}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{subgroup\_indices}}}
\pysigstopsignatures
\sphinxAtStartPar
List of indices for subgroup columns, if present.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
list

\end{description}\end{quote}

\end{fulllineitems}

\index{have\_subgroup (calzone.utils.data\_loader attribute)@\spxentry{have\_subgroup}\spxextra{calzone.utils.data\_loader attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.have_subgroup}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{have\_subgroup}}}
\pysigstopsignatures
\sphinxAtStartPar
Flag indicating whether subgroup information is present.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
bool

\end{description}\end{quote}

\end{fulllineitems}

\index{data (calzone.utils.data\_loader attribute)@\spxentry{data}\spxextra{calzone.utils.data\_loader attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.data}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{data}}}
\pysigstopsignatures
\sphinxAtStartPar
Raw data loaded from the CSV file.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{probs (calzone.utils.data\_loader attribute)@\spxentry{probs}\spxextra{calzone.utils.data\_loader attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.probs}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{probs}}}
\pysigstopsignatures
\sphinxAtStartPar
Probability values extracted from the data.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{labels (calzone.utils.data\_loader attribute)@\spxentry{labels}\spxextra{calzone.utils.data\_loader attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.labels}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{labels}}}
\pysigstopsignatures
\sphinxAtStartPar
Label values extracted from the data.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{subgroups\_class (calzone.utils.data\_loader attribute)@\spxentry{subgroups\_class}\spxextra{calzone.utils.data\_loader attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.subgroups_class}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{subgroups\_class}}}
\pysigstopsignatures
\sphinxAtStartPar
List of unique subgroup classes for each subgroup, if present.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
list

\end{description}\end{quote}

\end{fulllineitems}

\index{subgroups\_index (calzone.utils.data\_loader attribute)@\spxentry{subgroups\_index}\spxextra{calzone.utils.data\_loader attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.subgroups_index}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{subgroups\_index}}}
\pysigstopsignatures
\sphinxAtStartPar
List of indices for each subgroup class, if present.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
list

\end{description}\end{quote}

\end{fulllineitems}

\index{\_\_init\_\_() (calzone.utils.data\_loader method)@\spxentry{\_\_init\_\_()}\spxextra{calzone.utils.data\_loader method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.data_loader.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{self}}\sphinxparamcomma \sphinxparam{\DUrole{n}{data\_path}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Initializes the data\_loader object and loads data from a CSV file.

\end{fulllineitems}

\index{\_\_init\_\_() (calzone.utils.data\_loader method)@\spxentry{\_\_init\_\_()}\spxextra{calzone.utils.data\_loader method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:id0}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{data\_path}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Initializes the data\_loader object and loads data from the specified file.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{data\_path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Path to the CSV file containing the data.

\end{description}\end{quote}

\sphinxAtStartPar
The method performs the following steps:
1. Loads the header from the CSV file.
2. Checks for the presence of subgroup information.
3. Loads the data based on the presence or absence of subgroup information.
4. Extracts probability values and labels from the loaded data.
5. If subgroups are present, extracts subgroup classes and their indices.

\sphinxAtStartPar
Note:
\sphinxhyphen{} If there is a header, it must be in the format: proba\_0,proba\_1,…,subgroup\_1(optional),subgroup\_2(optional),…,label
\sphinxhyphen{} If there is no header, the columns must be in the order of proba\_0,proba\_1,…,label

\end{fulllineitems}


\end{fulllineitems}

\index{fake\_binary\_data\_generator (class in calzone.utils)@\spxentry{fake\_binary\_data\_generator}\spxextra{class in calzone.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.fake_binary_data_generator}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{calzone.utils.}}\sphinxbfcode{\sphinxupquote{fake\_binary\_data\_generator}}}{\sphinxparam{\DUrole{n}{alpha\_val}}\sphinxparamcomma \sphinxparam{\DUrole{n}{beta\_val}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\sphinxAtStartPar
A class for generating fake binary data and applying miscalibration.

\sphinxAtStartPar
This class provides methods to generate binary classification data
and apply different types of miscalibration to the probabilities.
\index{alpha\_val (calzone.utils.fake\_binary\_data\_generator attribute)@\spxentry{alpha\_val}\spxextra{calzone.utils.fake\_binary\_data\_generator attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.fake_binary_data_generator.alpha_val}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{alpha\_val}}}
\pysigstopsignatures
\sphinxAtStartPar
Alpha parameter for the beta distribution.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
float

\end{description}\end{quote}

\end{fulllineitems}

\index{beta\_val (calzone.utils.fake\_binary\_data\_generator attribute)@\spxentry{beta\_val}\spxextra{calzone.utils.fake\_binary\_data\_generator attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.fake_binary_data_generator.beta_val}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{beta\_val}}}
\pysigstopsignatures
\sphinxAtStartPar
Beta parameter for the beta distribution.
\begin{quote}\begin{description}
\sphinxlineitem{Type}
\sphinxAtStartPar
float

\end{description}\end{quote}

\end{fulllineitems}

\index{\_\_init\_\_() (calzone.utils.fake\_binary\_data\_generator method)@\spxentry{\_\_init\_\_()}\spxextra{calzone.utils.fake\_binary\_data\_generator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.fake_binary_data_generator.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{alpha\_val}}\sphinxparamcomma \sphinxparam{\DUrole{n}{beta\_val}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Initialize the fake binary data generator.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{alpha\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Alpha parameter for the beta distribution.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{beta\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Beta parameter for the beta distribution.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{abraitary\_miscal() (calzone.utils.fake\_binary\_data\_generator method)@\spxentry{abraitary\_miscal()}\spxextra{calzone.utils.fake\_binary\_data\_generator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.fake_binary_data_generator.abraitary_miscal}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abraitary\_miscal}}}{\sphinxparam{\DUrole{n}{logits}}\sphinxparamcomma \sphinxparam{\DUrole{n}{miscal\_function}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Apply arbitrary miscalibration to the input logits.

\sphinxAtStartPar
This function allows for the application of any custom miscalibration
function to the input logits.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{logits}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Input logits of shape (n\_samples, 2).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{miscal\_function}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}) \textendash{} Function to apply miscalibration to the logits.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{numpy.ndarray} \textendash{} Miscalibrated probabilities of shape (n\_samples, 2).

\end{description}\end{quote}

\end{fulllineitems}

\index{generate\_data() (calzone.utils.fake\_binary\_data\_generator method)@\spxentry{generate\_data()}\spxextra{calzone.utils.fake\_binary\_data\_generator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.fake_binary_data_generator.generate_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{generate\_data}}}{\sphinxparam{\DUrole{n}{sample\_size}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Generate fake binary classification data.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{sample\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples to generate.

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{X} (\sphinxstyleemphasis{numpy.ndarray}) \textendash{} Array of shape (sample\_size, 2) containing probabilities for each class.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{y\_true} (\sphinxstyleemphasis{numpy.ndarray}) \textendash{} Array of shape (sample\_size,) containing true binary labels.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{linear\_miscal() (calzone.utils.fake\_binary\_data\_generator method)@\spxentry{linear\_miscal()}\spxextra{calzone.utils.fake\_binary\_data\_generator method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.fake_binary_data_generator.linear_miscal}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{linear\_miscal}}}{\sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{miscal\_scale}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Apply linear miscalibration to the input probabilities.

\sphinxAtStartPar
This function transforms the input probabilities to logits,
applies a linear scaling, and then converts back to probabilities.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{X}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Input probabilities of shape (n\_samples, 2).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{miscal\_scale}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Scale factor for miscalibration.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{numpy.ndarray} \textendash{} Miscalibrated probabilities of shape (n\_samples, 2).

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{find\_optimal\_prevalence() (in module calzone.utils)@\spxentry{find\_optimal\_prevalence()}\spxextra{in module calzone.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.find_optimal_prevalence}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.utils.}}\sphinxbfcode{\sphinxupquote{find\_optimal\_prevalence}}}{\sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_calculate}\DUrole{o}{=}\DUrole{default_value}{1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{epsilon}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}10}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Find the optimal adjustment prevalence using scipy.optimize.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True labels.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_calculate}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The class index to optimize for. Default is 1.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{epsilon}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Small value to avoid numerical instability. Default is 1e\sphinxhyphen{}10.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{optimal\_prevalence} (\sphinxstyleemphasis{float}) \textendash{} The optimal prevalence.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{adjusted\_probabilities} (\sphinxstyleemphasis{numpy.ndarray}) \textendash{} The adjusted probabilities using the optimal prevalence.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{loss() (in module calzone.utils)@\spxentry{loss()}\spxextra{in module calzone.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.loss}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.utils.}}\sphinxbfcode{\sphinxupquote{loss}}}{\sphinxparam{\DUrole{n}{adjusted\_prevalence}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_calculate}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate the loss function for prevalence adjustment.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{adjusted\_prevalence}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The adjusted prevalence.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True labels.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_calculate}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The class index to calculate loss for. Default is 1.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{float} \textendash{} Calculated loss value.

\end{description}\end{quote}

\end{fulllineitems}

\index{make\_roc\_curve() (in module calzone.utils)@\spxentry{make\_roc\_curve()}\spxextra{in module calzone.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.make_roc_curve}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.utils.}}\sphinxbfcode{\sphinxupquote{make\_roc\_curve}}}{\sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_plot}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the Receiver Operating Characteristic (ROC) curve for binary or multiclass classification.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True labels of the data. Shape (n\_samples,).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities of the positive class. Shape (n\_samples, n\_classes).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_plot}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The class to plot the ROC curve for. If None, plots the ROC curve for each class. Default is None.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{fpr} (\sphinxstyleemphasis{array}) \textendash{} False Positive Rate for the selected class or each class. Shape (n\_points,).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{tpr} (\sphinxstyleemphasis{array}) \textendash{} True Positive Rate for the selected class or each class. Shape (n\_points,).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{roc\_auc} (\sphinxstyleemphasis{float or array}) \textendash{} Area Under the ROC Curve (AUC) for the selected class or each class. If class\_to\_plot is not None, returns a float. If class\_to\_plot is None, returns an array of shape (n\_classes,).

\end{itemize}

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}\begin{itemize}
\item {} 
\sphinxAtStartPar
The input arrays y\_true and y\_proba must have the same number of samples.

\item {} 
\sphinxAtStartPar
The input array y\_proba must have probabilities for each class in a multiclass problem.

\item {} 
\sphinxAtStartPar
The input array y\_proba must not contain any NaN values.

\end{itemize}
\end{sphinxadmonition}
\subsubsection*{Example}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y\PYGZus{}true} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y\PYGZus{}proba} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mf}{0.2}\PYG{p}{,} \PYG{l+m+mf}{0.8}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{0.6}\PYG{p}{,} \PYG{l+m+mf}{0.4}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{0.3}\PYG{p}{,} \PYG{l+m+mf}{0.7}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{0.9}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{0.4}\PYG{p}{,} \PYG{l+m+mf}{0.6}\PYG{p}{]}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{fpr}\PYG{p}{,} \PYG{n}{tpr}\PYG{p}{,} \PYG{n}{roc\PYGZus{}auc} \PYG{o}{=} \PYG{n}{roc\PYGZus{}curve}\PYG{p}{(}\PYG{n}{y\PYGZus{}true}\PYG{p}{,} \PYG{n}{y\PYGZus{}proba}\PYG{p}{,} \PYG{n}{class\PYGZus{}to\PYGZus{}plot}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{reliability\_diagram() (in module calzone.utils)@\spxentry{reliability\_diagram()}\spxextra{in module calzone.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.reliability_diagram}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.utils.}}\sphinxbfcode{\sphinxupquote{reliability\_diagram}}}{\sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_bins}\DUrole{o}{=}\DUrole{default_value}{10}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_plot}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{is\_equal\_freq}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{n}{save\_path}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the reliability diagram for a binary or multi\sphinxhyphen{}class classification model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True labels of the samples. Can be a binary array or a one\sphinxhyphen{}hot encoded array.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities for each class. Shape should be (n\_samples, n\_classes).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_bins}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of bins to divide the predicted probabilities into. Default is 10.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_plot}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Index of the class to plot the reliability diagram for. If None, the diagram will be computed for all classes. Default is None.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{is\_equal\_freq}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} If True, the bins will be equally frequent. If False, the bins will be equally spaced. Default is False.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{reliabilities} (\sphinxstyleemphasis{array\sphinxhyphen{}like}) \textendash{} Array of accuracies for each bin. Shape depends on the value of class\_to\_plot.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{confidences} (\sphinxstyleemphasis{array\sphinxhyphen{}like}) \textendash{} Array of average confidences for each bin. Shape depends on the value of class\_to\_plot.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{bin\_edges} (\sphinxstyleemphasis{array\sphinxhyphen{}like}) \textendash{} Array of bin edges.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{bin\_counts} (\sphinxstyleemphasis{array\sphinxhyphen{}like}) \textendash{} Array of counts for each bin.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}\begin{itemize}
\item {} 
\sphinxAtStartPar
The reliability diagram is a graphical tool to assess the calibration of a classification model. It plots the average predicted probability against the observed accuracy for each bin of predicted probabilities.

\item {} 
\sphinxAtStartPar
If y\_true is a binary array, it will be converted to a one\sphinxhyphen{}hot encoded array internally.

\item {} 
\sphinxAtStartPar
If class\_to\_plot is not None, the reliability diagram will be computed only for the specified class. Otherwise, it will be computed for all classes.

\item {} 
\sphinxAtStartPar
The number of bins determines the granularity of the reliability diagram. Higher values result in more bins and a more detailed diagram.

\end{itemize}
\end{sphinxadmonition}

\end{fulllineitems}

\index{removing\_nan() (in module calzone.utils)@\spxentry{removing\_nan()}\spxextra{in module calzone.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.removing_nan}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.utils.}}\sphinxbfcode{\sphinxupquote{removing\_nan}}}{\sphinxparam{\DUrole{n}{y\_true}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_predict}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_proba}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Remove rows containing NaN values from input arrays.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_true}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True labels.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_predict}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted labels.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y\_proba}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Predicted probabilities.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{y\_true} (\sphinxstyleemphasis{array\sphinxhyphen{}like}) \textendash{} Cleaned version of y\_true with NaN rows removed.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{y\_predict} (\sphinxstyleemphasis{array\sphinxhyphen{}like}) \textendash{} Cleaned version of y\_predict with NaN rows removed.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{y\_proba} (\sphinxstyleemphasis{array\sphinxhyphen{}like}) \textendash{} Cleaned version of y\_proba with NaN rows removed.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{softmax\_to\_logits() (in module calzone.utils)@\spxentry{softmax\_to\_logits()}\spxextra{in module calzone.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.utils.softmax_to_logits}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.utils.}}\sphinxbfcode{\sphinxupquote{softmax\_to\_logits}}}{\sphinxparam{\DUrole{n}{probabilities}}\sphinxparamcomma \sphinxparam{\DUrole{n}{epsilon}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}10}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Convert softmax probabilities to logits.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{probabilities}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Input probabilities.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{epsilon}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Small value to avoid log(0). Default is 1e\sphinxhyphen{}10.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{numpy.ndarray} \textendash{} Computed logits.

\end{description}\end{quote}

\end{fulllineitems}



\subsection{calzone.vis module}
\label{\detokenize{calzone:module-calzone.vis}}\label{\detokenize{calzone:calzone-vis-module}}\index{module@\spxentry{module}!calzone.vis@\spxentry{calzone.vis}}\index{calzone.vis@\spxentry{calzone.vis}!module@\spxentry{module}}
\sphinxAtStartPar
Visualization functions for the Calibration Measure package.
\index{plot\_reliability\_diagram() (in module calzone.vis)@\spxentry{plot\_reliability\_diagram()}\spxextra{in module calzone.vis}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.vis.plot_reliability_diagram}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.vis.}}\sphinxbfcode{\sphinxupquote{plot\_reliability\_diagram}}}{\sphinxparam{\DUrole{n}{reliabilities}}\sphinxparamcomma \sphinxparam{\DUrole{n}{confidences}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bin\_counts}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bin\_edges}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{line}\DUrole{o}{=}\DUrole{default_value}{True}}\sphinxparamcomma \sphinxparam{\DUrole{n}{error\_bar}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{n}{z}\DUrole{o}{=}\DUrole{default_value}{1.96}}\sphinxparamcomma \sphinxparam{\DUrole{n}{title}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Reliability Diagram\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{save\_path}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{return\_fig}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{n}{custom\_colors}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{dpi}\DUrole{o}{=}\DUrole{default_value}{150}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Plot a reliability diagram to visualize the calibration of a model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{reliabilities}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Empirical frequencies for each bin.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{confidences}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Mean predicted probabilities for each bin.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bin\_counts}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Number of samples in each bin.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bin\_edges}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Edges of the bins. If None, assumes equal\sphinxhyphen{}spaced bins.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{line}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} If True, plot lines connecting points. If False, plot as a bar chart. Defaults to True.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{error\_bar}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} If True, add error bars to the plot. Defaults to False.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{z}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Z\sphinxhyphen{}score for calculating Wilson score interval. Defaults to 1.96.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{title}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Title of the plot. Defaults to ‘Reliability Diagram’.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{save\_path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Path to save the figure. If None, figure is not saved. Defaults to None.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_fig}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} If True, return the figure object. Defaults to False.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{custom\_colors}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} List of custom colors for multi\sphinxhyphen{}class plots. Defaults to None.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dpi}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} DPI for saving the figure. Defaults to 150.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{matplotlib.figure.Figure, optional} \textendash{} The figure object if return\_fig is True.

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_roc\_curve() (in module calzone.vis)@\spxentry{plot\_roc\_curve()}\spxextra{in module calzone.vis}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{calzone:calzone.vis.plot_roc_curve}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{calzone.vis.}}\sphinxbfcode{\sphinxupquote{plot\_roc\_curve}}}{\sphinxparam{\DUrole{n}{fpr}}\sphinxparamcomma \sphinxparam{\DUrole{n}{tpr}}\sphinxparamcomma \sphinxparam{\DUrole{n}{roc\_auc}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_to\_plot}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{title}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}ROC Curve\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{save\_path}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{dpi}\DUrole{o}{=}\DUrole{default_value}{150}}\sphinxparamcomma \sphinxparam{\DUrole{n}{return\_fig}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Plots the Receiver Operating Characteristic (ROC) curve.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fpr}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} False Positive Rate values.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{tpr}} (\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} True Positive Rate values.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{roc\_auc}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{array\sphinxhyphen{}like}}) \textendash{} Area Under the ROC Curve (AUC) value(s).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{class\_to\_plot}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The class to plot. If None, plots all classes. Defaults to None.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{title}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Title of the plot. Defaults to ‘ROC Curve’.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{save\_path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} Path to save the figure. If None, the figure is not saved. Defaults to None.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dpi}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The resolution in dots per inch for saving the figure. Defaults to 150.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_fig}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} If True, returns the figure object instead of displaying it. Defaults to False.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{matplotlib.figure.Figure or None} \textendash{} The figure object if return\_fig is True, otherwise None.

\end{description}\end{quote}

\sphinxAtStartPar
This function creates a matplotlib figure showing the ROC curve(s).

\end{fulllineitems}



\subsection{Module contents}
\label{\detokenize{calzone:module-calzone}}\label{\detokenize{calzone:module-contents}}\index{module@\spxentry{module}!calzone@\spxentry{calzone}}\index{calzone@\spxentry{calzone}!module@\spxentry{module}}

\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{c}
\item\relax\sphinxstyleindexentry{calzone}\sphinxstyleindexpageref{calzone:\detokenize{module-calzone}}
\item\relax\sphinxstyleindexentry{calzone.metrics}\sphinxstyleindexpageref{calzone:\detokenize{module-calzone.metrics}}
\item\relax\sphinxstyleindexentry{calzone.utils}\sphinxstyleindexpageref{calzone:\detokenize{module-calzone.utils}}
\item\relax\sphinxstyleindexentry{calzone.vis}\sphinxstyleindexpageref{calzone:\detokenize{module-calzone.vis}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}