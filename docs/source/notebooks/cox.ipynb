{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COX calibration analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Background\n",
    "\n",
    "Cox calibration analysis is both a logistic recalibration technique and a method to examine the current calibration of a model.To perform the analysis, we first need to fit a new logistic regression model using logit(log odds, aka $\\log\\frac{\\hat{p}}{1-\\hat{p}}$) as the predictor variable and the outcome the predictor variable. \n",
    "\n",
    "$$\n",
    "p_{new} = \\frac{1}{1+e^{-(a + b \\cdot \\log\\frac{\\hat{p}}{1-\\hat{p}})}}\n",
    "$$\n",
    "\n",
    "In the case of perfect calibration, $P(Y=1|p=\\hat{p}) = \\hat{p}$ and the new probability $p_{new}$ is equal to the original probability $\\hat{p}$. That means $a=0$ and $b=1$. If $b>1$, the model is under-confidence at high probabilities and over-confidence at low probabilities for the class-of-interest.  If $b<1$, the model is over-confidence at high probabilities and under-confidence at low probabilities for the class-of-interest. If $a>0$, the model is over-confidence at all probabilities for the class-of-interest.  If $a<0$, the model is under-confidence at all probabilities for the class-of-interest. The confidence interval of $a$ and $b$ can be used to guide the calibration of the model. The user can also choose to fix $a=0$ and fit for $b$ only and vice versa, then there will be not interaction between $a$ and $b$ and the confidence interval can be used as a statistical test to test for perfect calibration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros of Cox calibration analysis\n",
    "\n",
    "Cox calibration analysis doesn't depend on binning of data, which is a big advantage since common metrics such as ECE/MCE and HL test all depend on binning and we have shown that changging binning can lead to different results. We can also use it to perform statistical tests by fixing $a$ to 0 and test whether $b=1$ and the other way around to test for perfect calibration. Also, the fitted value of $a$ and $b$ can tell us how the model is miscalibrated, whether is a overall under or over-confidence or it is over-confident in some range and under-confident in another range. For example, if the $a$ doesn't close to 0 while $b$ is close to 1, it means that it is likely due to prevalence shift. See more details in the prevalence adjustment notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cons of Cox calibration analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cox Calibration analysis can only access weak calibration and there only capture a certain type of miscalibration (general over/underconfident). A model can have a $a=0$ and $b=1$ and still be miscalibrated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Cox slope and intercept with calzone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to calculate the Cox slope and intercept. Calling the Cox function give you more control on the calculation, including fixing $a=0$ or $b=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5000\n",
      "Model:                          Logit   Df Residuals:                     4998\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Wed, 25 Sep 2024   Pseudo R-squ.:                  0.4438\n",
      "Time:                        16:15:33   Log-Likelihood:                -1927.5\n",
      "converged:                       True   LL-Null:                       -3465.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0450      0.040     -1.123      0.262      -0.123       0.034\n",
      "x1             0.9942      0.029     34.212      0.000       0.937       1.051\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "from calzone.utils import reliability_diagram,data_loader\n",
    "from calzone.metrics import cox_regression_analysis\n",
    "import numpy as np\n",
    "\n",
    "### loading the data\n",
    "wellcal_dataloader = data_loader(data_path=\"../../../example_data/simulated_welldata.csv\")\n",
    "\n",
    "### calculating cox slope and intercept\n",
    "cox_slope, cox_intercept,cox_slope_ci,cox_intercept_ci = cox_regression_analysis(wellcal_dataloader.labels, wellcal_dataloader.probs,class_to_calculate=1,print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
